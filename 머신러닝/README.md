# 머신러닝

### 목차
- [1강. 머신러닝 소개](#1강-머신러닝-소개)
  - [머신러닝의 개념](#머신러닝의-개념)
  - [머신러닝의 처리 과정](#머신러닝의-처리-과정)
  - [머신러닝의 기본 요소](#머신러닝의-기본-요소)
  - [머신러닝에서의 주제](#머신러닝에서의-주제)
  - [학습 시스템 관련 개념](#학습-시스템-관련-개념)
- [2강. 지도학습: 분류](#2강-지도학습-분류)
  - [분류의 개념](#분류의-개념)
  - [베이즈 분류기](#베이즈-분류기)
  - [K-최근접이웃 분류기](#K-최근접이웃-분류기)
- [3강. 지도학습: 회귀](#3강-지도학습-회귀)
  - [회귀의 개념](#회귀의-개념)
  - [선형회귀](#선형회귀)
  - [선형회귀의 확장](#선형회귀의-확장)
  - [로지스틱 회귀](#로지스틱-회귀)
- [5강. 데이터 표현: 특징추출](#5강-데이터-표현-특징추출)
  - [선형변환에 의한 특징추출](#선형변환에-의한-특징추출)
  - [주성분분석법](#주성분분석법)
  - [선형판별분석법](#선형판별분석법)
  - [거리 기반 차원 축소 방법](#거리-기반-차원-축소-방법)
- [6강. 앙상블 학습](#6강-앙상블-학습)
  - [앙상블 학습의 개념](#앙상블-학습의-개념)
  - [배깅과 보팅](#배깅과-보팅)
  - [부스팅](#부스팅)
  - [결합 방법](#결합-방법)
- [7강. 결정 트리와 랜덤 포레스트](#7강-결정-트리와-랜덤-포레스트)
  - [결정 트리](#결정-트리)
    - [결정 트리를 이용한 분류](#결정-트리를-이용한-분류)
    - [결정 트리를 이용한 회귀](#결정-트리를-이용한-회귀)
  - [랜덤 포레스트](#랜덤-포레스트)
    - [랜덤 포레스트를 이용한 분류와 회귀](#랜덤-포레스트를-이용한-분류와-회귀)
- [8강. SVM과 커널법](#8강-SVM과-커널법)
  - [선형 분류기](#선형-분류기)
  - [SVM 분류기](#SVM-분류기)
  - [커널법](#커널법)
- [9강. 신경망 (1)](#9강-신경망-1)
  - [신경망 개요](#신경망-개요)
    - [뉴런, 신경망 구조, 학습](#뉴런-신경망-구조-학습)
    - [신경망의 응용적 이해](#신경망의-응용적-이해)
  - [다층 퍼셉트론](#다층-퍼셉트론)
- [10강. 신경망 (2)](#10강-신경망-2)
  - [다층 퍼셉트론의 학습](#다층-퍼셉트론의-학습)
  - [응용: 숫자인식](#응용-숫자인식)
- [12강. 딥러닝 (2)](#12강-딥러닝-2)
  - [기본 순환 신경망(RNN)](#기본-순환-신경망RNN)
  - [LSTM과 GRU](#LSTM과-GRU)
- [13강. 딥러닝 응용 (1)](#13강-딥러닝-응용-1)
  - [컴퓨터비전 응용](#컴퓨터비전-응용)
  - [객체인식을 위한 CNN 모델](#객체인식을-위한-CNN-모델)
  - [영상이해를 위한 딥러닝](#영상이해를-위한-딥러닝)
  - [영상변환 및 생성을 위한 딥러닝](#영상변환-및-생성을-위한-딥러닝)
- [14강. 딥러닝 응용 (2)](#14강-딥러닝-응용-2)
  - [자연어처리 응용](#자연어처리-응용)
  - [자연어처리를 위한 머신러닝 기법](#자연어처리를-위한-머신러닝-기법)
  - [언어 모델을 위한 딥러닝](#언어-모델을-위한-딥러닝)

### 교재 및 강의 구성
![image](https://user-images.githubusercontent.com/61646760/185350045-f4cea6ef-9456-49f8-959e-4b991fbc138f.png)

## 1강. 머신러닝 소개
### 머신러닝의 개념
- 딥러닝 ⊂ 머신러닝 ⊂ 인공지능
  - 머신러닝은 인공지능의 한 분야
  - 머신러닝 중 심층 신경망을 기반으로 하는 머신러닝 방법을 딥러닝이라고 함
- **인공지능(Artificial Intelligence, AI)**
  - 인간 지능을 모방하여 문제 해결을 위해 사람처럼 학습/이해하는 기계를 만듦
  - **약 인공지능(weak AI)**
    - 실제 지능의 소유 여부와 상관없이 **지능적인 것처럼 행동**하는 기계
    - 단지 정의된 특정 목적을 달성하고 문제를 해결하는 능력
  - **강 인공지능(strong AI)**
    - 지능의 모방이 아닌 **실제로 인간처럼 생각**하는 기계
    - 스스로 문제 정의 및 해결, 지속적인 학습, 자아, 감정 등의 광범위한 지적 능력을 포함
    - Artificial General Intelligence (AGI), Human-Level AI
- 인공지능의 역사  
  ![image](https://user-images.githubusercontent.com/61646760/185351677-b81bca09-3d49-47a2-97f2-1fce556267a1.png)
  - 인공지능의 성장 과정  
    ![image](https://user-images.githubusercontent.com/61646760/185351905-2ed8a7a2-77da-49dc-bf2f-192352b000ea.png)
- 머신러닝이란?
  - 기계학습
  - 인간이 갖고 있는 고유의 지능적 기능인 학습 능력을 기계를 통해 구현하기 위한 접근 방법
  - 주어진 데이터를 분석하여 그로부터 **일반적인 규칙이나 새로운 지식을 기계 스스로가 자동으로 추출**하기 위한 접근 방법  
    ![image](https://user-images.githubusercontent.com/61646760/185353424-720c0e6f-69b7-4a71-a1a8-6ddb763e5b87.png)
    - 규칙 기반 프로그래밍은 규칙을 지정해 주지만, 머신러닝은 규칙을 스스로 도출함
  - 왜 필요한가?
    - 데이터의 다양한 변형을 다루기 위해
    - **명시적 지식 표현, 프로그래밍이 어렵거나 불가능한 경우** 유용
- 딥러닝이란?
  - 심층 학습(deep learning)
  - 심층 신경망 기반의 머신러닝 분야
    - 입력층, 출력층 외에 은닉층이 많음
### 머신러닝의 처리 과정
![image](https://user-images.githubusercontent.com/61646760/186606200-2950960e-bde3-4e0f-8c58-507f9c96c79a.png)
### 머신러닝의 기본 요소
- 데이터와 데이터 분포
  - 데이터 표현  
    ![image](https://user-images.githubusercontent.com/61646760/186635791-e0086546-ea04-462d-bfc5-3118616e56c7.png)
    - 열 벡터(column vector)의 전위행렬(transpose)인 행 벡터(row vector)로 표기
  - 데이터 집합의 분포 특성
    - 해당 공간상에서 점들이 분포된 모양
    - 2차원 데이터 집합의 산점도(scatter plot)  
      ![image](https://user-images.githubusercontent.com/61646760/186636571-008ee68a-e32e-4364-9159-e3563e9a1db8.png)
- **특징 추출(feature extraction)**
  - 주어진 데이터를 처리하는 데 핵심이 되는 정보를 추출하는 것  
    ![image](https://user-images.githubusercontent.com/61646760/186637022-06fba006-dcea-4998-ab4d-56c75979eb17.png)
  - 목적 : 비용(계산량, 메모리) 절약, 데이터에 포함된 불필요한 정보의 제거
  - 사영(projection)에 의한 특징 추출  
    ![image](https://user-images.githubusercontent.com/61646760/186637225-de9cc5b9-1455-4ea5-8e4f-aca01f854d57.png)
- **성능 평가(performance evaluation)**
  - **학습 시스템(Learning System)**
    - 데이터로부터 학습을 통해 추출하고자 하는 정보를 표현하는 시스템  
      ![image](https://user-images.githubusercontent.com/61646760/186637805-7da3fb7f-9ac7-4af9-b2fe-bc5d5a2a7ae1.png)
    - 입·출력 매핑 형태의 함수로 정의
    - 학습 : 데이터를 이용하여 함수 `𝑓`를 찾는 것 → 학습 시스템의 매개변수 `𝜽`를 찾는 것
      - 학습의 궁극적 목표 : 앞으로 주어질 새로운 데이터에 대한 성능을 최대화하는 것
  - **목적 함수(objective function)**
    - 주어진 데이터 집합을 이용하여 학습 시스템이 달성해야 하는 목표를 기계가 알 수 있는 수학적 함수로 정의한 것
  - **오차 함수(error function)**
    - 대표적인 목적 함수
      - 손실 함수(loss function), 비용 함수(cost function)라고도 함
    - 학습 시스템의 출력 값과 원하는 출력 값의 차이(‘오차’)로 정의
    - 학습의 목적 : 오차를 최소화하는 것
  - 오차 함수를 이용한 성능 평가 기준
    - **학습 오차(training error)**  
      ![image](https://user-images.githubusercontent.com/61646760/186639261-e423ec0c-1234-4f9e-8422-03ad746cbfb2.png)
      - 학습에 사용된 데이터(‘학습 데이터’) 집합에 대해 계산된 오차
    - **테스트 오차(test error)**  
      ![image](https://user-images.githubusercontent.com/61646760/186639778-4961c5af-83cb-4fea-a1a4-40e476805867.png)
      - 학습에 사용되지 않은 새로운 데이터(‘테스트 데이터’) 집합에 대해 계산된 오차
      - **경험 오차(empirical error)**
    - **일반화 오차(generalization error)**  
      ![image](https://user-images.githubusercontent.com/61646760/186639984-b8661340-efa9-4d9c-8b85-f77d227da3de.png)
      - 관찰될 수 있는 모든 데이터 분포 전체에 대해 정의되는 오차
      - 실제 계산이 불가해서 테스트 오차로 대신하여 평가
  - 일반화 오차의 추정
    - **교차검증법(cross validation method)**
      - 제한된 데이터 집합을 이용하여 일반화 오차에 좀 더 근접한 오차 값을 얻어 내기 위한 방법
      - **K-분절 교차검증법(K-fold cross validation)**  
        ![image](https://user-images.githubusercontent.com/61646760/186640487-7b88b2fd-e97c-442f-96ad-c003b3ff9552.png)
### 머신러닝에서의 주제
- 데이터 분석
  - **분류(classification)**
    - 입력 데이터가 어떤 부류(class)에 속하는지를 자동으로 판단하는 문제
      - `예) ~인식 (숫자인식, 얼굴인식, 생체인식)`
    - 베이즈 분류기, K-최근접이웃 분류기, 결정 트리, 랜덤 포레스트, SVM, 신경망(MLP, CNN, LSTM 등)
  - **회귀(regression)**
    - 입력 변수와 출력 변수 사이의 매핑 관계를 분석
      - `예) 시계열 예측 : 시장 예측, 환율 예측, 주가 예측 등`
    - 선형회귀, 비선형회귀, 로지스틱 회귀, SVM, 신경망(MLP, RBF, CNN, LSTM)
  - **군집화(clustering)**
    - 데이터 집합을 서로 비슷한 몇 개의 그룹(군집, cluster)으로 묶는 문제
      - `예) 데이터 그룹화, 영상 분할`
    - 분류 문제와 달리 클래스 정보가 주어지지 않음
    - K-평균 군집화, 계층적 군집화, 가우시안 혼합 모델, 신경망(SOM)
- 데이터 표현
  - **특징 추출(feature extraction)**
    - 원래 데이터로부터 데이터 분석에 적용하기 좋은 특징을 찾아내는 문제
      - `예) 영상 데이터의 차원 축소, 데이터 시각화`
    - 딥러닝에서는 **Representation learning**이라고 함
    - 주성분분석(PCA), 선형판별분석(LDA), MDS, t-SNE
- **분류(classification)**
  - 분류 시스템의 입·출력 관계  
    ![image](https://user-images.githubusercontent.com/61646760/186642140-fe2126c7-1585-420c-8536-37d37a8da47d.png)
  - 학습 결과 : <strong>결정 경계(decision boundary)</strong>와 **결정 함수(decision function)**
  - 학습 목표 : 분류 오차를 최소화하는 최적의 결정 경계 `𝑔(𝒙;𝜽)=0`를 찾는 것
  - 성능 평가 척도  
    ![image](https://user-images.githubusercontent.com/61646760/186642520-6f06f098-9a5c-4ed1-ab35-0fa468b6621d.png)
    - 분류율(classification rate)
    - 분류 오차(classification error)
  - 2차원 분류 문제의 예  
    ![image](https://user-images.githubusercontent.com/61646760/186642800-7e6671d5-7ed7-4bd2-9bba-3eb94814efdc.png)
- **회귀(regression)**
  - 회귀 시스템의 입·출력의 관계  
    ![image](https://user-images.githubusercontent.com/61646760/188251410-70337ed3-96d7-4c67-baec-b41e490867fc.png)
  - 학습 결과 : 회귀 함수(regression function)
  - 학습 목표 : 회귀 오차를 최소화하는 최적의 회귀 함수 `𝑦=𝑓(𝒙;𝜽)`를 찾는 것  
    ![image](https://user-images.githubusercontent.com/61646760/188251488-fa12c227-3b8f-4bcd-b818-934509a8a983.png)
  - **제곱 오차(squared error)**  
    ![image](https://user-images.githubusercontent.com/61646760/188251478-fd803582-eb08-4201-b8d3-8ff16fcfd113.png)
- **군집화(clustering)**
  - 군집화 시스템의 입·출력의 관계  
    ![image](https://user-images.githubusercontent.com/61646760/188251538-4afe5f23-09ee-4683-a2ca-1c68cde5d5d3.png)
  - 학습 결과 : K개의 서로소(disjoint)인 부분집합(클러스터)
  - 학습 목표 : 최적의 클러스터의 집합을 찾는 것
    - 클러스터 내의 분산은 최소화, 클러스터 간의 분산은 최대화  
      ![image](https://user-images.githubusercontent.com/61646760/188251576-d0e1d1d1-77c0-419a-afa8-fe3b9fda45ae.png)
- **특징 추출(feature extraction)**
  - 특징추출 시스템의 입·출력의 관계  
    ![image](https://user-images.githubusercontent.com/61646760/188251806-46056a91-a366-4694-8641-19fb1bf56af7.png)
  - 학습 결과 : 변환 함수(embedding function)
  - 학습 목표 : 분석 목적에 따라 달라짐
    - `예) 차원 축소 : 원래 데이터가 가지는 정보로부터의 손실량 최소화`  
      ![image](https://user-images.githubusercontent.com/61646760/188251860-c61352a3-eba9-4e79-8d1a-ba2bf70b18d7.png)
### 학습 시스템 관련 개념
- 머신러닝의 유형  
  ![image](https://user-images.githubusercontent.com/61646760/188251893-85263aa5-318c-4ee0-957a-381fc8f3ea38.png)
  - **지도학습, 교사학습(supervised learning)**
    - 학습할 때 시스템이 출력해야 할 목표 출력 값(교사)을 함께 제공
    - **분류, 회귀**
  - **비지도학습, 비교사학습(unsupervised learning)**
    - 학습할 때 목표 출력 값에 대한 정보가 없음
    - **군집화**
  - **준지도학습, 반지도학습(semi-supervised learning)**
    - 지도학습 + 비지도학습
    - 클래스 레이블링 비용을 줄이려는 목적
  - **강화학습(reinforcement learning)**
    - 출력 값에 대한 교사 신호가 ‘보상(reward)’ 형태로 제공
    - 교사 신호는 정확한 값이 아니고, 즉시 주어지지 않음
- 학습 시스템의 복잡도  
  ![image](https://user-images.githubusercontent.com/61646760/188252218-79b5987b-1247-4c4b-b876-3f18e9aa8a9c.png)
- **과다적합(overfitting)**
  - 학습 시스템이 학습 데이터에 대해서만 지나치게 적합한 형태로 결정 경계가 형성되는 현상  
    ![image](https://user-images.githubusercontent.com/61646760/188252103-551b7e27-dccd-4e7e-85ba-b580a935cfc1.png)
    - 검증 오차가 증가하기 시작하는 지점이 최적의 복잡도
  - 원인 : 학습 데이터의 확률적 잡음과 학습 데이터 개수의 부족
  - 영향 : 일반화 성능 저하 초래
- 학습 시스템의 복잡도를 조정하는 방법
  - 다양한 변형을 가진 충분한 학습 데이터 사용
  - 조기 종료 방법
  - 정규항을 가진 오차 함수 사용
  - 모델 선택 방법
- 머신러닝의 고급 주제
  - **앙상블 학습(ensemble learning)**
    - 복수 개의 간단한 학습 시스템을 결합하여 일반화 성능을 향상시킴
  - **능동 학습(active learning)**
    - 학습 과정에서 데이터를 선별적으로 선택하여 수행
  - **메타 학습과 자동 머신러닝(meta-learning, auto ML)**
    - 학습 시스템의 복잡도 등의 하이퍼파라미터까지 학습을 통해 최적화
  - **지속/증분 학습(continual/incremental learning)**
    - 기존에 학습된 내용에 대한 손실 없이 새로운 내용을 추가로 학습

## 2강. 지도학습: 분류
### 분류의 개념
- 데이터 분류
  - 입력 데이터를 이미 정의된 몇 개의 클래스로 구분하는 문제
  - `예) 숫자인식, 얼굴인식 등`
  - 베이즈 분류기, K-최근접이웃 분류기, 결정 트리, 랜덤 포레스트, SVM, 신경망(MLP, CNN, LSTM 등)
- 분류기의 입출력 관계  
  ![image](https://user-images.githubusercontent.com/61646760/188248175-e9f8ffc8-ac4f-4278-93e5-07418b3dab9c.png)
  - 학습 결과 : 결정경계와 결정함수
- 결정경계 `𝑔(𝒙;𝜽)`를 얻는 두 가지 접근법
  - **확률 기반 방법**
    - `𝑃(𝐶_𝑘|𝒙)`를 추정하여 분류
    - **베이즈 분류기**
  - **데이터 기반 방법**
    - 데이터 간의 관계를 바탕으로 분류
    - **K-최근접이웃 분류기**
### 베이즈 분류기
- 확률 분포에 기반한 분류의 개념  
  ![image](https://user-images.githubusercontent.com/61646760/188248333-34a7fe72-8efe-4d20-b001-b357654c00b0.png)
### K-최근접이웃 분류기

## 3강. 지도학습: 회귀
### 회귀의 개념
- **회귀(regression)**
  - 입력 변수와 출력 변수 사이의 매핑 관계를 찾는 것
    - 입력과 출력 간의 관계를 나타내는 함수 `𝑓`를 찾는 것
    - `예) 시계열 예측 → 주가 예측, 환율 예측 등`  
      ![image](https://user-images.githubusercontent.com/61646760/188299053-629c629e-3b8f-49c7-9179-b8431e4d1537.png)
  - 선형회귀, 비선형회귀, 로지스틱 회귀, SVM, 신경망(MLP, RBF, CNN, LSTM)
- 입력·출력의 관계  
  ![image](https://user-images.githubusercontent.com/61646760/188299375-6a24560e-1659-4311-8e51-3143650437e9.png)
  - `𝒙_𝑖` : 입력
  - `𝑦_𝑖` : 목표 출력 값(target output)
  - 분류 문제와의 차이
    - 출력 값 형태의 차이
    - 분류는 이산적인 값을 갖는 class label, 회귀는 연속적인 값을 갖는 실수
- 학습 결과 : 회귀 함수
- 학습 목표 : 예측 오차를 최소화하는 최적의 회귀 함수 `𝑦=𝑓(𝒙;𝜽)`를 찾는 것
  - **최소제곱법(least square method)** : 제곱 오차 = (목표 출력 값 - 𝒙에 따른 실제 출력 값)의 제곱  
    ![image](https://user-images.githubusercontent.com/61646760/188299532-a0cc751a-d36e-47ef-a833-63d55d55d502.png)
- 보간법(interpolation)과 회귀
  - 데이터를 가장 잘 표현하는 직선/곡선을 찾는 경우  
    ![image](https://user-images.githubusercontent.com/61646760/188299703-cead80a9-c4d7-4140-a5c3-32a3c1aa60d3.png)
    - 보간 곡선 : 제곱 오차가 0이지만 매우 복잡
    - 회귀 직선 : 작은 오차, 전체적인 데이터의 경향을 보여 주는 입출력의 관계 표현에 적합
    - 주어진 데이터가 어느 정도의 노이즈, 관측 오차를 포함하고 있다는 가정하에, 보간 곡선과 같이 모든 점들을 지나는 정확한 곡선을 찾는 것은 별 의미가 없고, 전체적인 데이터가 어떤 경향을 갖는 보여 주는 직선 또는 곡선을 찾는 것이 보다 합리적임
### 선형회귀
- **선형회귀(linear regression)**
  - 데이터집합 `𝐷={(𝑥_𝑖, 𝑦_𝑖)}_𝑖=1,⋯,𝑁 (𝑥_𝑖∈𝑅, 𝑦_𝑖∈𝑅)`에 대해 `(𝑥, 𝑦)` 관계(입력-출력 관계)를 설명할 수 있는 선형 함수 `𝑦=𝑤_1𝑥 + 𝑤_0 + 𝑒`를 찾는 것  
    ![image](https://user-images.githubusercontent.com/61646760/188301357-37e5050b-beca-4515-a45d-1d2f0053f7d4.png)
    - `𝑤_1` : 기울기
    - `𝑤_0` : 절편
    - `𝑒` : 오차 또는 잔차(residual)
    - 선형 함수상의 `𝑦_𝑖` 값과 실제 `𝑦` 값은 `𝑒_𝑖`의 오차를 가짐
- 좋은 선형회귀 모델
  - 모든 데이터에 대해서 잔차가 가능한 작아야 함  
    ![image](https://user-images.githubusercontent.com/61646760/188302130-0d4a537a-6f88-44a2-a736-1e9f9d4fbce1.png)
    - 즉 `𝑒_𝑖`가 작아야 함
  - 평가 기준
    - 모든 데이터에 대한 잔차의 합  
      ![image](https://user-images.githubusercontent.com/61646760/188302177-e9c9250a-e296-455d-bb20-f9b473876a48.png)
      - 부적합한 방법  
        ![image](https://user-images.githubusercontent.com/61646760/188302304-556193d9-7c7e-4a85-8253-29a57ca6e4fa.png)
        - `𝑒_𝑖`가 양수일 수도, 음수일 수도 있으므로 실선일 수도, 점선일 수도 있음 (두 직선이 생성)
    - **잔차의 제곱의 합**  
      ![image](https://user-images.githubusercontent.com/61646760/188302197-8d61ff80-6b5d-4f66-8dff-00865324ea7f.png)
      - 주어진 데이터 집합에 대해 유일한 직선을 생성
        - 원래 `1/𝑁`이 시그마 앞에 있어야 하지만, 없어도 무방하여 제거함
      - **평균 제곱 오차(MSE, Mean Squared Error)**
- 최적의 회귀 매개변수
  - 오차 함수  
    ![image](https://user-images.githubusercontent.com/61646760/188302399-873432db-d12a-4454-960e-f88e9c0aec08.png)
    - 평균 제곱 오차(MSE)
    - 오차 함수에서 찾아야 할 패러미터는 `𝑤_1`(기울기)과 `𝑤_0`(절편)
  - 최적의 매개변수  
    ![image](https://user-images.githubusercontent.com/61646760/188302407-04944ac2-785b-44e2-89aa-14dc374b286a.png)
    - `𝑤_1`(기울기)과 `𝑤_0`(절편)를 구하는 공식
      - 데이터를 바탕으로 `𝑤_1`을 먼저 계산하고, 그를 바탕으로 대입해서 `𝑤_0`를 계산하면 됨
    - `𝒙_bar`는 `𝒙`의 평균, `𝑦_bar`는 `𝑦`의 평균
- 매개변수 계산 과정
  ![image](https://user-images.githubusercontent.com/61646760/188303516-93d7cb3b-ebab-4a39-864e-5d7d171be8ac.png)
  - 색칠 칸은 각각 '각 매개변수에 대해서 편미분 수행', '연립방정식 형태로 정리'
  - `𝑤_0`에 대해 편미분, `𝑤_1`에 대해 편미분 후 -2는 날리고 시그마를 배분하여 `𝑤_0`과 `𝑤_1`에 해당하는 이원 일차 연립방정식 형태로 정리 후 풀어 주면 최적의 매개변수 `𝑤_1`과 `𝑤_0`을 구할 수 있음
  - 예제  
    ![image](https://user-images.githubusercontent.com/61646760/188304116-302571b9-7592-4b68-aee9-d781e4121454.png)
    - 상단 '데이터', 하단 '회귀함수'
- 예측과 평가
  - 회귀 함수를 사용한 새 데이터 `𝑥_𝑛𝑒𝑤`에 대한 예측  
    ![image](https://user-images.githubusercontent.com/61646760/188304256-b0dac235-5b36-4bb0-a6cd-2a4b41dea3f9.png)
  - 테스트 데이터 집합 ![image](https://user-images.githubusercontent.com/61646760/188304296-4b4e013f-10a7-48bb-b311-68c3fd41ea52.png)에 대한 평가 기준
    - **평균 제곱 오차(Mean Squared Error: MSE)**  
      ![image](https://user-images.githubusercontent.com/61646760/188304359-52f0609b-57ce-43cd-9384-8fd4147a8e8e.png)
      - 목표 출력 값과 실제(시스템) 출력 값의 차 제곱의 평균
    - **평균 제곱근 오차(Root Mean Square Error: RMSE)**  
      ![image](https://user-images.githubusercontent.com/61646760/188304368-1673cde3-47f3-4301-9871-ddcaf6ba840d.png)
      - 제곱에 루트를 씌움
      - 루트 때문에 제곱이 사라지므로 목표 출력 값과 실제 출력 값 간의 차이를 보다 직관적으로 파악할 수 있음
- **다변량 선형 회귀(Multivariate Linear Regression)**
  - n차원 입력 벡터 `𝒙 = {𝑥_1, 𝑥_2, ⋯ , 𝑥_𝑛}`
    - 하나의 데이터 `𝒙`가 n차원 즉, 𝑛개의 값으로 이루어짐  
      ![image](https://user-images.githubusercontent.com/61646760/188305013-3d0fed0d-1ae5-4dad-b9f7-e66b60a1873c.png)
      - y축은 수축기 혈압
      - 나이, 몸무게가 주어졌을 때 수축기 혈압을 찾는 선형 평면
  - 입력이 여러 개의 값으로 이루어진 경우 (실제로 많은 경우)
  - 회귀함수  
    ![image](https://user-images.githubusercontent.com/61646760/188305093-fe175ebe-77f7-4b5c-91be-5a848c6771a0.png)
    - 입력(`𝑥`)은 𝑛개, 패러미터(`𝑤`)는 𝑛+1개
  - 행렬 형태의 표현  
    ![image](https://user-images.githubusercontent.com/61646760/188305164-668568e2-65ba-44db-9ef2-b14779d38356.png)
    - 빈칸은 '데이터 집합', '경우'
    - 데이터가 1개인 경우
      - `x̃` (x tilde) : 패러미터 𝑤는 𝑛+1개의 값을 가지므로, 데이터(`𝒙`)-패러미터(`𝑤`) 값 간 차원을 맞추기 위해, 원래 주어진 데이터 `𝒙`에 1이라는 값을 더한 `x̃`를 설정함
      - `𝑤^Tx̃`와 같은 행렬 형태로 표현 가능
    - 데이터가 여럿인 경우
      - 각각의 `𝑥_𝑖`는 n차원으로 이루어짐
      - 각각의 `𝑥_𝑖`에 1을 집어 넣고, 이를 `x̃_𝑖`로 표기
  - 오차 함수  
    ![image](https://user-images.githubusercontent.com/61646760/188305462-0f2b65e5-4d8a-47bf-a2bb-61b8f88ba485.png)
    - 목표 출력 값(`𝑦`)과 실제(시스템) 출력 값 `𝑿𝑤`의 차의 2차 노름(norm) 형태로 오차 함수가 주어짐
      - [나무위키 : 노름(수학)](https://namu.wiki/w/노름(수학))
  - 최적의 파라미터 `𝑤`  
    ![image](https://user-images.githubusercontent.com/61646760/188305482-28f76069-6e7e-4cc0-a060-b865679f3316.png)
    - 빈칸은 '를 곱하면'
    - 오차 함수를 최소화시키는 `𝑤`는, `𝑤`에 대해 오차 함수를 편미분하여 0이 되는 값
    - 행렬과 그 행렬의 역행렬을 곱하면 단위행렬이 되므로 좌변은 `𝑤`만 남음
    - 새 데이터 `𝑥_𝑛𝑒𝑤`에 대한 예측  
      ![image](https://user-images.githubusercontent.com/61646760/188305778-72bd2e82-97d2-4798-adaa-30242add6d94.png)
### 선형회귀의 확장
- 선형회귀의 한계
  - `𝑥`와 `𝑦`의 관계를 선형 매핑으로 표현할 수 없는 경우  
    ![image](https://user-images.githubusercontent.com/61646760/188305839-d9a97e51-4a0f-41eb-b632-97ca28fceb9f.png)
  - 선형화(linearization) 과정을 거친 후 선형회귀 적용
    - `𝑥`와 `𝑦`를 `x̃`와 `ỹ`로 적절히 변형한 후 선형 매핑 관계 `ỹ = 𝑚x̃ + 𝑏`를 찾는 방식
- 선형화(linearization)
  - 지수 형태  
    ![image](https://user-images.githubusercontent.com/61646760/188305930-2ab3d63b-c24c-4a11-967f-9aa721a9d84c.png)
    - 데이터 입출력의 관계가 지수 형태면 곧바로 선형회귀를 적용할 수 없음
    - 자연로그(ln)을 취해 선형화 과정을 거쳐야 함
      - `𝑥`와 `ln 𝑦`의 공간 그래프로 변경 후 선형회귀 적용 가능
  - 단순 거듭제곱 형태  
    ![image](https://user-images.githubusercontent.com/61646760/188306084-ecdc21c3-f3af-47dd-b9f1-7d4f0f51893f.png)
    - 로그를 취해 `log𝑥`와 `log𝑦`로 바꿔 선형회귀를 적용
  - 포화된 증가 형태  
    ![image](https://user-images.githubusercontent.com/61646760/188306148-2832d112-e6f6-419d-a3ac-c9e5e2684511.png)
    - 역수를 취하여 바뀐 공간에서 직선을 찾는 문제로 변형
- 다른 접근법
  - 보다 복잡한 형태의 곡선으로의 매핑을 위한 방법
  - **다항 회귀(polynomial regression)**
    - 고차다항식 사용  
      ![image](https://user-images.githubusercontent.com/61646760/188306261-127eff27-0079-4e65-9538-025fcc89ce15.png)
  - 비선형 입력 변환함수를 사용한 선형회귀  
    ![image](https://user-images.githubusercontent.com/61646760/188306273-73ba583c-4536-478a-96fa-0e1ca3943396.png)
  - **비선형회귀(nonlinear regression)**
    - 신경망과 같은 복잡한 비선형함수를 사용하는 방법
    - 커널을 이용하여 고차원 공간으로 매핑하는 SVM 적용
### 로지스틱 회귀
- **로지스틱 회귀(logistic regression)**
  - 범주형 데이터의 회귀
    - 선형회귀 분석의 종속변수(출력)를 범주형으로 확장한 것
      - 회귀의 출력은 기본적으로 실수(output∈R)
      - 출력을 실수가 아닌 범주(category), class label로 만든 것
    - 분류 문제에 적용 가능
      - 즉, **분류 문제에 적용할 수 있도록 회귀를 확장**시킨 것
    - 입력 값이 각 클래스에 속하는 확률 값을 회귀분석으로 예측  
      ![image](https://user-images.githubusercontent.com/61646760/188306446-e0afd23e-eb22-4b96-9366-3343ef828eca.png)
      - 우측 빈칸이 '로지스틱 회귀'
      - 0과 1이 class label(범주)
- **로지스틱 함수(logistic function)**
  - 𝑥 ∈ (−∞, ∞)를 항상 0, 1 범위로 매핑하는 S자형 함수  
    ![image](https://user-images.githubusercontent.com/61646760/188306531-82cfb737-1be0-4714-a1be-ba82e092d6fa.png)
  - 로지스틱 함수를 이용한 분류  
    ![image](https://user-images.githubusercontent.com/61646760/188306778-9fab2f31-989b-446a-8744-60f2bfa7836a.png)
    - 함수의 출력값 : 클래스 레이블에 대한 사후확률 `𝑃(𝑦=1|𝑥)`
      - 즉, 입력 값 𝑥가 주어졌을 때, class label이 1인 조건부 확률  
      ![image](https://user-images.githubusercontent.com/61646760/188306638-bb9c25e2-562d-46d8-a8c2-ddd7aa0ec890.png)
    - 로지스틱 함수를 이용한 사후확률 추정  
      ![image](https://user-images.githubusercontent.com/61646760/188306666-fbeb46e4-252e-4802-9770-6407dd287e81.png)
      - 결국 구하고 싶은 것은 `𝑚`과 `𝑏`
  - 파라미터 `𝑚`과 `𝑏` 값에 따른 함수의 형태  
    ![image](https://user-images.githubusercontent.com/61646760/188306884-5b5d757a-0cef-4f32-970e-e3e2f6a9f9fa.png)
- **오즈비(odds ratio, 승산비)**  
  ![image](https://user-images.githubusercontent.com/61646760/188306978-47f5b15a-30ef-4bd9-9bf6-434906f55cb3.png)
  - 분모 `1 - 𝑥가 주어졌을 때 𝑦가 1일(class C2에 속할) 확률` : C1에 속할 확률
  - 분자는 C2에 속할 확률
  - 즉, 입력 𝑥가 C1에 속할 확률과 C2에 속할 확률의 비율을 오즈비라고 함
    - `𝑥`가 C2에 속하면 분자가 크므로 오즈비는 1보다 큼
    - `𝑥`가 C1에 속하면 분모가 크므로 오즈비는 1보다 작음
- **로짓 함수(logit function)**
  - 오즈비에 대해 로그를 취한 것  
    ![image](https://user-images.githubusercontent.com/61646760/188306991-c3621b10-32ac-4d46-9bd6-1b1f35ed5d14.png)
    - 오즈비에 자연로그를 취하면 exponential이 사라짐  
      ![image](https://user-images.githubusercontent.com/61646760/188307206-4e2f7cda-998a-49ed-81dd-806cd0a3b1e9.png)
    - 로짓 함수(`𝑚𝑥 + 𝑏`)가 0보다 작으면 `𝑥`는 C1에 속함
- 로지스틱 회귀의 결정경계  
  ![image](https://user-images.githubusercontent.com/61646760/188307005-73bff439-0012-44ce-a2af-feccec3d5c23.png)
  - 로짓 함수를 0으로 둬서 판별함수, 결정경계로 사용 가능
- 로지스틱 회귀의 매개변수 추정
  - 데이터  
    ![image](https://user-images.githubusercontent.com/61646760/188307380-5f3e0a72-a348-4734-aae2-75171c99c41e.png)
  - `𝑝(𝑦|𝑥)`의 확률함수 : 베르누이 분포를 따름  
    ![image](https://user-images.githubusercontent.com/61646760/188307394-843ebda4-47ec-4eec-8fb0-3ef173e6342a.png)
  - 목적 함수 : `𝐷`에 대한 로그 우도(log likelihood)  
    ![image](https://user-images.githubusercontent.com/61646760/188307443-920fb150-bb79-43fb-9812-dd23a1dad03c.png)
    - 목적 함수를 이용해 `𝑚`과 `𝑏`를 찾아야 함
  - 추정 : **최대 우도 추정법(maximum likelihood estimation)**  
    ![image](https://user-images.githubusercontent.com/61646760/188307491-d42ddaeb-e3e7-493d-b244-eecc01368fd0.png)
    - 수치적 최적화 방법으로 반복적 추정을 통해 최적화
    - `𝑚`과 `𝑏`에 대해 편미분
  - 파라미터 `𝑚`과 `𝑏`의 추정 후 새로운 데이터의 분류 과정  
    ![image](https://user-images.githubusercontent.com/61646760/188307510-789afada-02af-4cd6-9197-be57c94e4c1e.png)
### 정리하기
![image](https://user-images.githubusercontent.com/61646760/188298889-9fbf6ece-1c46-4063-bbca-e23142f37116.png)

## 5강. 데이터 표현: 특징추출
### 선형변환에 의한 특징추출
- **특징 추출(feature extraction)**  
  ![image](https://user-images.githubusercontent.com/61646760/189130124-cc837069-3a4f-4083-92f3-4762db727128.png)
  - 학습(데이터 분석)을 통해 변환함수 `Φ`를 찾는 것을 특징 추출이라고 함
    - `Φ`를 통해 𝑛차원의 입력 데이터 `𝑥`는 `𝑦`라는 `𝑚` 차원의 특징 벡터로 변환됨
  - 학습(특징 추출)의 목적
    - 분석에 불필요한 정보를 제거하고 **핵심 정보만 추출**
    - **차원 축소**를 통한 분석 시스템의 효율 향상
      - 계산량/메모리 감소, 성능 향상
- **변환함수(embedding function, transformation function)** 종류
  - **선형변환(linear transformation)**
    - 𝑛차원 열벡터 `𝒙`에 변환행렬 `𝐖(𝑛×𝑚)`를 곱하여 𝑚차원 특징을 획득  
      ![image](https://user-images.githubusercontent.com/61646760/189291893-5e8ed868-ce17-4f69-a8af-c3a47771623e.png)
      - `𝐖(𝑛×𝑚)`을 transpose한 것은 `(𝑚×𝑛)`이고, `𝒙`는 `(𝑛×1)`이므로, `𝑦`는 `(𝑚×1)`
    - 통계적 방법으로 특징벡터 `𝒚`가 원하는 분포가 되도록 하는 `𝐖`를 찾음
  - **비선형변환(nonlinear transformation)**
    - 복잡한 비선형 함수 `∅(𝒙)`를 이용하여 𝑛차원 벡터를 𝑚차원 벡터로 매핑
    - 사용 방법
      - 수작업(handcrafted)에 의한 특징추출
      - 표현학습(representation learning) : 딥러닝에서 주로 사용하는 용어
- **수작업에 의한 특징추출**
  - 입력 데이터의 특성과 분석 목적에 맞는 특징을 개발자가 설계함
    - 전통적인 방법 (여전히 사용)
      - 데이터 특성에 따라 다른 특징 사용
      - 어떤 특징을 사용할지는 개발자가 결정
    - 숫자 인식을 위한 특징  
      ![image](https://user-images.githubusercontent.com/61646760/189293737-e43efe76-c95b-456d-88be-2ab73a3e8795.png)
    - 영상 분석을 위한 특징 : 에지, 가로/세로 방향 성분 등
    - 문서 분석을 위한 특징 : 단어의 발생 빈도 등
- **표현학습(representation learning)**
  - 특징추출을 위한 비선형 변환함수를 신경망 등의 머신러닝 모델로 표현
  - 학습을 통해 분석이 잘 되도록 변환함수의 최적화가 가능
  - `예) 딥러닝 모델을 이용한 얼굴 인식용 특징추출 (CNN)`  
    ![image](https://user-images.githubusercontent.com/61646760/189294756-a5d31c76-ecbf-4422-9519-4231e1f06dc9.png)
- **선형변환에 의한 특징추출**
  - 차원 축소 관점에서의 특징추출
    - 데이터의 특성에 의존하지 않는 좀 더 일반적인 사용 가능
    - 데이터의 차원이 크다는 것은 많은 정보를 가지고 있다는 것
      - 많은 정보 중에는 불필요한 정보도 많음
      - 이를 처리로 돌리면 처리 성능을 높일 수 있음
    - 데이터의 차원이 커지면 성능도 계속 좋아질까?
      - 어느 정도까지는 좋아지지만 갑자기 안 좋아지는 구간이 있으며, 이를 차원의 저주라고 부름  
        ![image](https://user-images.githubusercontent.com/61646760/189297817-e6a739b3-ac51-4d57-810d-57f2f4c2e471.png)
      - **[차원의 저주(Curse of Dimensionality)](https://en.wikipedia.org/wiki/Curse_of_dimensionality)** : 차원이 증가함에 따라 모델의 성능이 나빠지는 현상
    - 차원 축소  
      ![image](https://user-images.githubusercontent.com/61646760/189298448-15970ecf-a932-479d-90a8-282adc215dbb.png)
      - 𝑛차원의 랜덤 벡터(`𝒙`)를 변환행렬 `𝐖`를 통해 𝑚차원의 특징 벡터(`𝑦`)로 축소 (당연히 𝑚은 𝑛보다 작음)  
        ![image](https://user-images.githubusercontent.com/61646760/189299236-b46c2339-174a-451e-82e3-240f5df22e74.png)
        - **특징값 `𝑦_𝑖` : `𝒙`를 `𝐖`의 열벡터 `𝒘_𝑖` 위로 사영한 값 (단, `𝒘_𝑖`는 단위벡터)**
          - **단위벡터(unit vector)** : 길이가 1인 벡터
  - 2차원 데이터 `𝒙`를 1차원 특징 `𝑦`로 변환
    - 벡터 `𝒙`를 `𝒘` 위로 사영 : `𝑦=𝑤^𝑇𝒙` (단, `𝒘`는 단위벡터)  
      ![image](https://user-images.githubusercontent.com/61646760/189468763-50fbb658-a387-4ee0-a63f-1f97a20d7c1d.png)
      - 벡터 `𝒙`를 `𝒘` 위로 사영(projection)한 결과 값이 특징벡터 `𝑦`
  - 3차원 데이터 : 2차원 특징추출  
    ![image](https://user-images.githubusercontent.com/61646760/189474079-9c9c70e0-b032-4788-aab1-16fddeb979b8.png)
    - `𝒙(3x1)`, 변환행렬 `𝐖`는 (크기가 1이라 단위벡터인) 2개의 열벡터(`𝒘_1`, `𝒘_2`)를 가짐
### 주성분분석법
### 선형판별분석법
### 거리 기반 차원 축소 방법

## 6강. 앙상블 학습
### 앙상블 학습의 개념
- **앙상블 학습(ensemble learning)**
  - 선형 분류기와 같은 간단한 학습기로 학습을 수행하지만, 복수 개의 학습기를 결합함으로써 결과적으로 더 좋은 성능을 가진 학습기를 만드는 방법  
    ![image](https://user-images.githubusercontent.com/61646760/192756330-49c7b2e0-c274-466d-9fe2-50472173ffb6.png)
    - 즉, **간단한 학습기를 결합해 사용함으로써 복잡한 학습기와 같은 성능**을 내는 것
      - 간단한 학습기는 구현이 쉬우나 성능이 떨어지고, 복잡한 학습기(SVM, 딥러닝 등)는 성능은 좋으나 학습을 통해 찾아야 할 패러미터가 많을 뿐 아니라 찾기 어렵고, 과적합을 통해 일반화 성능이 떨어지는 문제가 있을 수 있음
    - 그런데 어떤 학습기를 사용해, 어떻게 결합할 것인가?
- 학습기 결합의 고려 사항
  - 학습기의 차별화 방법
    - **학습 알고리즘의 차별화**
      - 접근 방법이 서로 다른 학습기 선택
        - `예) 베이즈 분류기&K-NN, 신경망&SVM`
      - 학습 알고리즘이 완전히 다른 학습기를 함께 사용
    - **모델 선택과 관련된 패러미터의 차별화**
      - K값이 서로 다른 복수의 K-NN, 은닉층의 뉴런 수가 서로 다른 복수의 MLP
        - `예) K 값을 5, 10, 15, 20 등등 여럿으로 줌`
    - **학습 데이터의 차별화**
      - 같은 모델을 사용하되 학습 데이터 집합을 달리하여 복수 개의 학습기를 생성
      - 이론적으로 성능이 증명되어 있음
        - 따라서 집중해서 살펴볼 것!!
  - 학습기 결합 방법
    - 병렬적 결합 : 각 학습기의 결과를 한번에 모두 함께 고려하여 하나의 최종 결과를 생성
    - 순차적 결합 : 각 학습기의 결과를 단계별로 결합
- 앙상블 학습의 개요  
  ![image](https://user-images.githubusercontent.com/61646760/192758277-4644644d-c822-474a-905f-9d61d217677c.png)
  - 학습 데이터 생성 방법에 따른 분류
    - 필터링(filtering)에 의한 방법 : **초기 부스팅 방법**, **캐스케이딩 방법**
      - 각 학습기의 학습 때마다 새로운 데이터를 생성하고, 이를 이미 학습이 완료된 학습기에 적용하여 제대로 처리되지 못하는 데이터들만 필터링하여 학습
    - 리샘플링(resampling)에 의한 방법 : **배깅 방법**, MadaBoost 방법
      - 각 학습기의 학습 때마다 학습 데이터를 새로 생성하지 않고, 주어진 전체 학습 데이터로부터 일부 집합을 추출하여 각 학습기를 학습
    - 가중치 조정(reweighting)에 의한 방법 : **AdaBoost 방법**
      - 모든 학습기에 대해 동일한 학습 데이터를 사용하되, 각 데이터에 대해 가중치를 주어 학습에 대한 영향도를 조정
### 배깅과 보팅
- 배깅과 보팅
  - 배깅(bagging) : 학습기를 선택하는 방법
  - 보팅(voting) : 학습기의 결과를 결합하는 방법
- **배깅(bagging)에 의한 학습**
  - “bootstrap aggregating”의 약자
  - 부트스트랩 방법을 앙상블 학습에 적용한 것
    - **부트스트랩(bootstrap)** : 제한된 데이터 집합을 이용하여 시스템의 학습과 평가를 동시에 수행하기 위한 리샘플링 기법
    - 즉, 하나의 데이터 집합에서 데이터를 일부분 추출하여 각각의 시스템을 학습시킨 것
  - 배깅에 의한 𝑀개의 서로 다른 학습기의 학습 과정
    1. 𝑁개의 데이터로 이루어진 학습 데이터 집합 𝑋를 준비하고, 학습을 위한 학습기 모델(`예) KNN, 베이즈 분류기, 신경망 등`)을 정의한다. **𝑀개의 학습기를 각각 학습시키기 위해 사용될 데이터 집합의 크기 Ñ**(Ñ≤𝑁)을 정한다.
    2. 𝑖번째 학습기 ℎ_𝑖(𝒙) 모델의 파라미터를 초기화하고, 학습 데이터 집합 𝑋로부터 Ñ개의 데이터를 랜덤하게 선출하여 데이터 집합 𝑋_𝑖를 만든다. 이때 같은 데이터가 중복해서 선출되는 것도 허락한다(복원 추출).
    3. 데이터 집합 𝑋_𝑖를 이용한 학습을 수행하여 최적화된 파라미터 𝜽_𝑖를 찾아 𝑖번째 학습기를 위한 판별함수 ℎ_𝑖(𝒙, 𝜽_𝑖)를 얻는다.
    4. ②~③ 과정을 𝑀번 반복하여 서로 다른 𝑀개의 학습기를 생성하고, 이들을 결합하여 최종 판별함수 𝑓(ℎ_1, ℎ_2, ⋯, ℎ_𝑀)을 찾는다.
  - 고려 사항
    - 데이터 집합의 크기 Ñ
      - 주어진 전체 학습 데이터 집합 𝑋의 크기 𝑁이 충분히 크지 않으면 Ñ과 𝑁은 같은 값으로 지정
      - 복원추출을 사용하므로 매 단계마다 생성되는 데이터의 집합은 동일하지 않음
    - 학습에 사용될 학습기의 모델
      - 학습기에 의해 찾아지는 판별함수가 데이터 집합의 변화에 민감한 모델을 선택하는 것이 바람직
        - 데이터 집합만 바꿔 적용하므로 
      - `예) 다층 퍼셉트론, 최근접이웃 분류기 등`
  - **배깅(bagging)으로 M개의 학습기를 만든 뒤, 학습기를 결합하기 위해 보팅(voting)을 사용**함
- **보팅(voting)에 의한 결합**
  - 보팅법(voting), “**committee machine**”
    - 𝑀개의 학습기 결과를 모두 동일한 정도로 반영하여 평균한 결과를 얻는 방법(“단순평균법”)
  - 보팅에 의한 결합함수  
    ![image](https://user-images.githubusercontent.com/61646760/192771093-7eb6924e-49df-4a2d-836b-f437779aba57.png)
    - 각각의 학습기가 도출한 결과를 다 더한 뒤 1/𝑀로 나눔으로써 평균을 내 줌
    - 이산적인 값이 나오는 분류 문제의 경우, 별도의 처리 과정이 필요
- 배깅과 보팅에 의한 결정경계  
  ![image](https://user-images.githubusercontent.com/61646760/193065578-0d321126-e6d2-4a88-98eb-3eaead0e4bc4.png)
  - 3개의 선형 분류기의 결정경계를 합쳐서 좀 더 복잡한 최종 결정경계(새로운 모델)를 얻음
- 배깅과 보팅에 의한 오차  
  ![image](https://user-images.githubusercontent.com/61646760/193065761-7b282856-d128-4c08-81ef-5f7072be340d.png)
  - 일반화 오차 : 학습에 사용되지 않은 나머지 모든 데이터에 대해 발생하는 오차
  - 일반적으로 각 학습기의 오차는 서로 독립적이지 않고 양의 상관관계를 가짐
    - 이론적으로는 일반화 오차가 1/𝑀만큼 줄어들 수 있지만, 현실적으로는 1/𝑀만큼의 일반화 오차의 감소 효과를 기대할 수 없음
### 부스팅
- **부스팅(boosting)**
  - 간단한 학습기들이 상호 보완적 역할을 할 수 있도록 **단계적으로 학습**을 수행하여 결합함으로써 성능을 증폭시키기 위한 방법
    - 먼저 학습된 학습기의 결과가 다음 학습기의 학습에 정보를 제공하여 이전 학습기의 결점을 보완
- **필터링에 의한 부스팅(boosting by filtering)**
  - 가장 처음 제안된 부스팅 방법 by Schapire  
    ![image](https://user-images.githubusercontent.com/61646760/193072916-9b555bfb-ee78-423b-a2b7-de8fc9ba6b9e.png)
    - X_1으로 h_1 학습
    - X_2는 h_1에서 잘못 결과를 낸 데이터와 바르게 결과를 낸 데이터 일부를 같은 비율로 섞어 만든 데이터를 통해 h_2 학습
      - 즉 h_2는 h_1이 잘 못한 것도 할 수 있게 학습
    - X_3는 h_1과 h_2 결과가 일치하지 않는 것만 모은 데이터를 통해 h_3 학습
    - 추론 과정 : h_1과 h_2의 결과가 일치하면 그 값이 곧 최종 결과
      - 불일치 시, h_3 결과가 최종 결과
  - 학습 데이터 규모가 매우 커야 함
    - “AdaBoost” 등장!
- **AdaBoost 알고리즘**
  - 같은 데이터 집합을 반복해서 사용
    - 즉, 데이터 집합은 하나만 있으면 됨
  - **학습할 때마다 각 데이터에 대한 가중치를 조정**하여 학습의 변화를 꾀함
    - “데이터의 중요도가 적응적으로 변한다”
      - **Adaptive + Boost = AdaBoost**
  - 학습 방법 + 결합 방법 (둘을 함께 고려)
    - 분류기의 중요도를 각 학습기의 결합 과정에서 결합계수로 사용
      - 이 분류기는 이만큼 중요하니 결합할 때도 이만큼 반영해 줘야 한다 같은 식
    - 단순한 보팅법에 가중치를 적용한 결합 방법  
      ![image](https://user-images.githubusercontent.com/61646760/193079854-1cc00a2b-8c9e-4ea8-9bfc-df6da2f7c9f4.png)
      - 가중치는 곧 분류기의 중요도인 `α_𝑖` (아래 참고)
      - 각 학습기의 중요도 `α_𝑖`를 가중치로서 곱해 주는 것이 곧 결합 방법
  - AdaBoost에 의한 분류기의 학습과 분류  
    ![image](https://user-images.githubusercontent.com/61646760/193075664-9aa4be5e-4a12-4287-b041-777052d31ca0.png)  
    ![image](https://user-images.githubusercontent.com/61646760/193075732-628fc420-d891-444b-a334-5426df88fe22.png)  
    ![image](https://user-images.githubusercontent.com/61646760/193075800-8271edf8-6061-4965-835d-791204e48675.png)
    - ①의 위첨자 `(1)`은 첫 번째 학습기, `j`는 데이터
    - ②-1에서 오분류율은 오류가 발생했을 때만 1이고, 제대로 처리됐을 때는 0
      - 즉, `ε_𝑖`는 오류가 발생한 데이터들의 가중치들의 합
    - ②-3의 `α_𝑖`는 결합 과정에서 결합계수로도 사용
      - `ε_𝑖`(오분류율)가 작을수록 `α_𝑖`(분류기의 중요도)가 커짐
  - AdaBoost 정리
    - **이전 단계의 분류기의 학습 결과를 활용**하여 **다음 단계의 학습에 사용될 데이터에 가중치를 부여**함으로써 분류기 간의 차별성 부여
    - 각각의 간단한 분류기의 오분류율(`ε_𝑖`)이 0.5보다 작은 조건만 만족하면 분류기의 결합을 통해 학습 데이터에 대한 오차를 기하급수적으로 감소시킬 수 있음을 보임(by Fruend& Schapire)
    - **최적화된 결합 가중치를 찾아 분류기들을 결합**
    - **두 개의 클래스에 대한 분류 문제에 적합**한 방법
      - 다중 클래스에 적용하려면? 각 클래스별로 판별함수를 만들거나 모든 클래스 쌍에 대해 판별함수를 만들어야 함
### 결합 방법

## 7강. 결정 트리와 랜덤 포레스트
### 결정 트리
- **결정 트리(decision tree)**
  - 주어진 문제에 관해 결정을 내리는 함수를 트리 형태로 구성
    - 분류 문제를 위해 개발되었으나, 회귀 문제로 확장됨 : **“CART”(Classification And Regression Trees)**
  - 뛰어난 설명력(explainability) 제공
    - 트리 구조에 각 입력 요소의 역할이 잘 표현되어 학습 결과를 설명
      - 즉, 결과가 왜 이렇게 나왔는지 그 이유를 쉽게 이해할 수 있음 → **설명 가능한 인공지능(eXplainable Artificial Intelligence, XAI)**
  - 과다적합 문제
    - 복잡한 함수의 표현 과정(트리를 깊게 만듦)에서 데이터의 노이즈에 민감한 문제 → 앙상블 학습기법을 결합한 방법(“랜덤 포레스트”) 등장
      - 즉, **랜덤 포레스트 = 결정 트리 + 앙상블 학습**
- 결정 트리의 예
  - `예) 세탁기 동작 여부(ON, OFF)를 결정하는 결정 트리`  
    ![image](https://user-images.githubusercontent.com/61646760/193394243-63ea6538-475c-4aff-ba87-0e15e872e18a.png)
    - 속성(판단을 내리는 데 사용하는 결정 요인) → 날씨, 습도, 세탁량
- 결정 트리 vs 규칙 기반의 표현  
  ![image](https://user-images.githubusercontent.com/61646760/193396523-ffdfb399-b1b2-4f39-b9ba-fcb9ed985309.png)
  - 결정 트리는 학습을 통해 자동 생성되지만, 규칙 기반으로 만들 경우 개발자가 일일이 수작업으로 작성해야 함
- 결정 트리의 학습
  - 학습 데이터의 예  
    ![image](https://user-images.githubusercontent.com/61646760/193396577-4314a793-57ce-44b2-9a43-3eeb94aa87ec.png)
    - 날씨, 온도, 습도, 세탁량에 따라 세탁기 동작 여부 결정
  - 학습 과정  
    ![image](https://user-images.githubusercontent.com/61646760/193396975-96cdb07d-2fcf-4097-8ac6-d2537c58c62d.png)
    - Step 1
      - 루트 노드의 속성으로 날씨를 선택
      - 날씨 속성이 가질 수 있는 값들의 경우는 3가지 (Sunny, Rainy, Cloudy)
      - 자식 노드로 세탁기 동작 여부의 값들을 모아 나열 (Sunny의 경우 OFF 2개, ON 3개)
        - 즉, 자식 노드에는 해당 노드에 들어가는 데이터의 클래스 레이블(ON / OFF)을 삽입
      - Rainy는 클래스 레이블이 모두 OFF이므로 더 이상 분할할 필요가 없음 (리프 노드의 클래스 레이블이 모두 상동하므로)
        - Sunny와 Cloudy는 분할해야 함
    - Step 2
      - 어떤 노드 속성을 사용할지 결정 (일단 Cloudy 먼저)
        - 날씨는 사용했으므로 세탁량(Amount) 선택
        - 세탁량은 총 2가지 값(Large, Small)을 가짐
      - Large는 모두 ON, Small은 모두 OFF로 클래스 레이블이 모두 같으므로, Amount의 리프 노드는 더 이상 분할할 필요가 없음
    - Step 3
      - 모든 노드가 리프 노드가 될 때까지 상기 과정을 반복
        - Sunny는 아직 ON/OFF가 섞여 있으니 분할해야 함
  - 각 노드에 어떤 속성(결정 요인)을 배정할 것인가?  
    ![image](https://user-images.githubusercontent.com/61646760/193397311-e4417e27-1cdc-44e4-b43b-17ce45dc7f50.png)
    - 자식 노드들이 하나의 클래스 레이블을 갖는 리프 노드가 될 때까지 계속해서 자식 노드를 분할해야 함
      - 분할을 적게 하는 것이 좋은 것!
      - Weather를 선택한 이유 : 총 14개 데이터 중 Rainy는 이미 다 분류돼 있으므로, 14-4 = 10개 데이터만 더 분할하면 됨
        - Temperature나 Amount는 총 14개를 분할해야 함
  - 속성 선택을 위한 평가 기준
    - **지니 불순도(Gini Impurity) I(N)**
      - 각 노드에 할당된 클래스 레이블이 얼마나 다른지 그 혼합 정도를 측정  
        ![image](https://user-images.githubusercontent.com/61646760/193397559-084d20b2-52dc-4afd-96a0-d9ecb155217f.png)
        - 많이 섞여 있을수록 불순도가 높은 것
      - `예) Weather의 Sunny 노드에 할당된 클래스 레이블은 ON과 OFF가 섞여 있음`
    - **지니 평가지수(Gini criterion) G(R_a)**
      - 속성 a를 갖는 부모 노드 R_a에서 자식 노드들의 지니 불순도의 가중합  
        ![image](https://user-images.githubusercontent.com/61646760/193397615-361e55fa-3ef4-4f73-b42f-af9decf71077.png)
    - `예) 세탁기 동작 여부 적용`  
      ![image](https://user-images.githubusercontent.com/61646760/193398309-45d211e4-62aa-439c-9b6b-a765764ac20b.png)
      - C_1의 지니 불순도
        - 1 - (1번째 클래스 비율 + 2번째 클래스 비율) = 0.48 ...
      - Weather 노드를 부모 노드로 갖는 속성에 대한 지니 평가지수
        - 가중치 : 전체 14개 데이터 중 C_1에 속하는 데이터가 5개이므로, 가중치는 5/14 ...
      - 지니 평가지수가 0.3429로 가장 낮은 G(R_weather)를 선택
        - 불순도가 가장 낮다는 건 데이터 분할을 적게 해도 된다는 의미
    - 어떤 노드에 적절한 속성을 선택하려면, 먼저 **지니 평가지수를 계산하여 그 값이 작은 것을 속성으로 선택하면 원하는 결정 트리**를 만들 수 있음
  - 속성 노드 선택을 위한 다양한 평가지수
    - **정보 이득(information gain)**
      - 데이터 집합의 분할 전후의 엔트로피의 차이
        - 엔트로피 : 데이터의 혼잡도. 낮을수록 데이터의 순도가 높음
      - 지니 불순도와 유사함
      - 분류 문제에서 주로 사용
    - **분산 감소량(reduction in variance)**
      - 모든 노드에 대한 분산의 가중 평균
        - 분산 : 데이터의 동질성을 표시. 데이터가 완전히 같으면 분산은 0
      - 회귀 문제에서 주로 사용
    - **Chi-square**
      - 부모 노드와 하위 노드 간 차이의 통계적 유의성을 활용
      - 분류 문제에서 주로 사용
#### 결정 트리를 이용한 분류
- 2차원 데이터의 예 : 𝑥_1, 𝑥_2 ∈ (0,1)  
  ![image](https://user-images.githubusercontent.com/61646760/193400373-f0899e41-362e-429d-bb9f-c6626c741894.png)
  - 가로 축은 𝑥_1, 세로 축은 𝑥_2
- 결정 트리  
  ![image](https://user-images.githubusercontent.com/61646760/193400224-e364a99c-5112-4b57-915d-a02e91f94524.png)
  - x[0]은 𝑥_1, x[1]은 𝑥_2로 보면 됨
  - 클래스 레이블이 0인 것은 C_1으로 생각하면 됨
  - C_1에 속한 데이터는 58개, C_2에 속한 데이터는 42개이므로 클래스 레이블은 0(C_1)
  - 속성 값에 따라 결정 경계로 계속 나누며 분할
    - 결정 트리의 깊이를 4로 설정해서 지니 불순도가 0이 아닌 터미널 노드가 있어도 멈춤
- 결정 경계  
  ![image](https://user-images.githubusercontent.com/61646760/193400512-fd2428df-f06f-484b-a5e3-296641ed7114.png)
  - 실제로 얻고 싶은 결정 경계는 최상단의 그래프
  - 깊이 4로는 계단형의 결정 경계가 만들어질 뿐 → 트리의 깊이를 더 깊게 해야??
  - 깊이 5인데 학습 데이터 처리가 끝났다면? 모든 리프 노드의 지니 불순도가 0이라는 것 (더 이상 분할할 것이 없음)
    - **깊이를 늘리는 데는 한계**가 있음! (과다적합의 문제도 있음)
      - 랜덤 포레스트 등장!
#### 결정 트리를 이용한 회귀
- 회귀 문제 : 𝑦 = 𝑓(𝑥_1, 𝑥_2), 𝑦 ∈ {0,1}  
  ![image](https://user-images.githubusercontent.com/61646760/193400771-2a953fa9-41ba-4f15-8182-a9f0b9123a42.png)
  - 기본적으로 트리 모양은 서로 동일
  - 리프 노드가 아닌 내부 노드의 속성, 속성 값이 서로 동일 (x[0] <= 0.555 ...)
  - 분류 문제와 회귀 문제의 차이
    - 분류 문제는 클래스 레이블이 0인지 1인지 판별
    - 회귀 문제는 '해당 노드에 속한 데이터의 목표 출력값의 평균' (목표 출력값에 얼마나 가까운가)
- 문제 유형에 따른 결정 트리의 출력
  - 분류 문제의 경우  
    ![image](https://user-images.githubusercontent.com/61646760/193400947-ecacdcd2-73f7-4f3c-81f7-922e6e060e7a.png)
    - 0.555, 0.182, 0.76에 따라 계단형의 결정 경계 형성
  - 회귀 문제의 경우  
    ![image](https://user-images.githubusercontent.com/61646760/193401003-940f6079-a411-4f64-be47-e3f369cd8d16.png)
    - 출력은 0과 1 사이에서 얼마나 목표 출력값에 가까운지를 출력
    - 0.555를 기준으로 나누고, 0.182를 기준으로 나누고, 0.76을 기준으로 나누어, 총 4개의 영역으로 나눔
    - 영역별로 0.727, 0.022, 0.97, 0.091의 높이를 가짐
- 일반적인 회귀 문제의 결정 트리  
  ![image](https://user-images.githubusercontent.com/61646760/193401128-af4586e0-503a-4ccf-a34d-464e187b3200.png)
  - 깊이 4는 비슷하지만, 깊이 6은 과다적합
    - 트리의 깊이가 깊어질수록 나뉘는 영역의 개수는 기하급수적으로 증가하고, 노이즈까지 학습함으로써 과다적합의 문제도 생김
- 결정 트리의 문제
  - **과다적합**
    - 모든 학습 데이터에 대해 완벽한 학습
  - 간단한 해결책
    - 조기종료(early stopping)
      - 데이터를 더 분할해도 성능이 향상되지 않을 때 노드의 분할을 종료
    - 가지치기(pruning)
      - 전체 트리를 만든 후 불필요한 노드들을 제거
  - 발전된 해결책 : “랜덤 포레스트”(random forest)
### 랜덤 포레스트
- **랜덤 포레스트(Random forest)**
  - 결정 트리와 앙상블 학습기법을 결합한 방법
    - 배깅 방법으로 데이터를 리샘플링하여 𝑀개의 결정 트리를 학습하고 결합하는 방법
      - 결합 방법 : 주로 보팅법(분류 문제일 때), 출력값의 평균(회귀 문제일 때)
    - 즉, 결정 트리를 여러 개 사용하여(앙상블 학습) 성능을 높이는 방법
  - “포레스트” : 𝑀개의 서로 다른 결정 트리의 결합
    - “랜덤” : 결정 트리 간의 차이가 랜덤으로 추출된 데이터 샘플에 기인
  - 장점
    - 간단한 학습기의 결합으로 복잡한 함수 표현 및 일반화 성능 향상
    - 높은 설명 능력, 빠른 학습
- 랜덤 포레스트의 생성 과정  
  ![image](https://user-images.githubusercontent.com/61646760/193401465-e96b8950-b525-4863-a42f-9cc444dfaed3.png)
  - 전체 데이터 집합 𝑋를 리샘플링하여 𝑋_1, 𝑋_2, ... 𝑋_𝑀의 데이터 집합 생성
  - 𝑋_1, 𝑋_2, ... 𝑋_M으로 결정 트리 제작 (각 데이터가 다르므로 서로 다른 형태의 트리 형성)
  - 분류 문제라면 '보팅'을 적용하여 하나의 결정 경계를 도출
- 랜덤 포레스트의 학습
  1. 𝑁개의 데이터로 이루어진 학습 데이터 집합 𝑋를 준비하고, 각 결정 트리의 학습에 사용될 데이터 집합의 크기 Ñ을 정한다.(Ñ ≤ 𝑁)
  2. 𝑖번째 결정 트리를 학습하기 위해 트리의 깊이를 결정하고, 학습 데이터 집합 𝑋로부터 Ñ개의 데이터를 랜덤하게 선출하여 데이터 집합 𝑋_𝑖를 만든다. 이때 같은 데이터가 중복해서 선출되는 것도 허락한다(복원추출).
  3. 데이터 집합 𝑋_𝑖를 이용하여 결정 트리를 학습하여 𝑖번째 판별함수(또는 회귀함수) ℎ_𝑖(𝒙)를 얻는다.
  4. ②~③ 과정을 𝑀번 반복하여 서로 다른 𝑀개의 결정 트리를 생성하고, 이들을 결합하여 최종 판별함수(또는 회귀함수) 𝑓(ℎ_1, ℎ_2, ... ℎ_𝑀)을 찾는다.
#### 랜덤 포레스트를 이용한 분류와 회귀
- 랜덤 포레스트를 이용한 분류  
  ![image](https://user-images.githubusercontent.com/61646760/193401899-0a590e9a-77fc-4ced-a47f-169a222d5b85.png)
  - 결정 트리를 1개, 3개, 10개, 100개 쓴 그래프
  - 결정 트리를 많이 쓸수록 원하는 결정 경계에 근접해짐
- 랜덤 포레스트를 이용한 회귀  
  ![image](https://user-images.githubusercontent.com/61646760/193401910-4142e934-d7f4-419a-a6e4-1000fa360481.png)
  - 결정 트리를 많이 쓸수록 원하는 결정 함수에 근접해짐
  - 과다적합도 많이 완화됨

## 8강. SVM과 커널법
### 선형 분류기
- 학습 시스템(e.g. 분류기)의 복잡도와 일반화 오차의 관계  
  ![image](https://user-images.githubusercontent.com/61646760/193439026-e5e00046-a9df-4a79-96de-f482fa305d6e.png)
  - 학습 데이터
    - 파란 선 : 직선 형태(선형)의 분류기 (학습 오차 2)
    - 점선 : 비선형의 결정 경계를 사용하면 정확도가 올라감 (학습 오차 0)
  - 실제 데이터
    - 일반화 오차는 5(선형):0(비선형)
    - 또 다른 경우는 6(선형):10(비선형)
      - 비선형 분류기가 더 큰 일반화 오차를 가짐
      - 과다적합 : 학습 데이터에 대해 너무나 학습이 잘된 것
  - 과다학습을 피하고 일반화 오차를 줄이기 위해서는 **학습 시스템의 복잡도를 적절히 조정**하는 것이 중요
    - SVM 등장!
- 선형 초평면 분류기
  - **선형 분류기(linear classifier)**
    - 선형 판별함수를 기반으로 분류를 수행하는 학습 시스템
      - 분류 시스템의 복잡도가 가장 낮으며, 분류 성능도 좋지 못함
      - 과다적합의 발생을 피할 수 있음
    - **SVM** : 일반화 오차를 최소화할 수 있는 방향으로 학습이 이루어지도록 설계된 선형 분류기
  - **초평면(hyperplane)**
    - 3차원 공간 속의 평면을 일반화하여 얻는 개념
    - 2차원의 초평면은 직선(1차원), 3차원의 초평면은 평면(2차원), n차원의 초평면은 n-1차원 공간
      - 즉, 그것이 그려진 공간의 차원보다 한 차원 낮은 공간
  - 입력 𝒙에 대한 선형 초평면 판별함수  
    ![image](https://user-images.githubusercontent.com/61646760/193439469-68b5ea90-af42-4365-8bde-14b2d57b6123.png)
    - 𝑖=2면(𝒙_1, 𝒙_2) 2차원이므로 선형 초평면은 직선(1차원), 𝑖=3이면 선형 초평면은 평면(2차원)
    - 결정 규칙  
      ![image](https://user-images.githubusercontent.com/61646760/193439850-30c1016a-8667-4f9f-9d13-a7d30f54232d.png)
    - 최소 학습 오차를 만족하는 선형 결정 경계는 여럿이 존재 → SVM **마진(margin) 개념** 도입  
      ![image](https://user-images.githubusercontent.com/61646760/193439898-696ec5e9-b343-4402-979f-8b406efba2e0.png)
### SVM 분류기
- **서포트 벡터 머신(SVM: Support Vector Machine)**
  - 최대 마진 분류기를 일반화한 모델
- **최대 마진 분류기(maximum margin classifier)**
  - **마진(margin)** : 학습 데이터들 중에서 결정경계에 가장 가까운 데이터로부터 결정경계까지의 거리
    - **서포트 벡터(support vector)** : 결정경계에 가장 가까운 곳에 위치한 데이터
  - 결정경계에 따른 마진과 서포트 펙터의 차이  
    ![image](https://user-images.githubusercontent.com/61646760/193440412-9da9419d-2c9f-46a1-8cb2-6c3c96ea1942.png)
    - 마진이 넓어지면 두 클래스의 분류가 보다 분명해짐
    - 최대 마진 분류기를 SVM이라고도 부름
  - 최대 마진을 가진 선형 결정경계(초평면)를 얻기 위한 선형 판별함수  
    ![image](https://user-images.githubusercontent.com/61646760/193440766-a4b47e44-c32e-4c21-9869-a08da4926131.png)
  - 한 점 𝒙에서 결정경계까지의 거리  
    ![image](https://user-images.githubusercontent.com/61646760/193440856-f20e228c-7164-42fb-bab5-faa340a89fff.png)
    - 𝒙와 결정경계 간 거리는 d
    - 서포트 벡터 χ(chi)로 결정경계가 1과 -1이 되게 할 수 있음
- 마진 계산  
  ![image](https://user-images.githubusercontent.com/61646760/193441339-9314950f-00e4-4c3f-9897-0978d4915989.png)
  - 플러스 평면 : C_1(빨강)에 있는 서포트 벡터(χ+)를 지나는 평면 (결정경계 1)
  - 마이너스 평면 : C_2(파랑)에 있는 서포트 벡터(χ-)를 지나는 평면 (결정경계 -1)
  - 마진(M) : `M = |χ+ - χ-| = 2/∥𝑤∥`
    - 마진을 최대화하여 일반화 오차를 최소화해야 함 → 분모(`∥𝑤∥`)를 최소화하면 됨
    - SVM의 학습은 `∥𝑤∥`를 최소화하는 방향으로 이루어짐
- SVM의 학습
  - 과정  
    ![image](https://user-images.githubusercontent.com/61646760/193441770-0a812db5-e9d2-401d-b2a2-2aaeb89720ae.png)  
    ![image](https://user-images.githubusercontent.com/61646760/193441780-f3e966ab-5813-43ed-84e3-1a82130c58b9.png)  
    ![image](https://user-images.githubusercontent.com/61646760/193441788-f69d8142-0770-44e3-9818-29cdb4b15b05.png)
    1. 목적함수와 다른 조건을 동시에 만족해야 하는 경우 **라그랑주 승수법** 사용
        - **라그랑주 승수법(Lagrange multiplier method)** : 프랑스의 수학자 조세프루이 라그랑주(Joseph-Louis Lagrange)가 제약 조건이 있는 최적화 문제를 풀기 위해 고안한 방법
        - 라그랑주 승수법은 어떠한 문제의 최적점을 찾는 것이 아니라, 최적점이 되기 위한 조건을 찾는 방법. 즉, 최적해의 필요조건을 찾는 방법.
    2. 라그랑주 승수 α를 포함하는 라그랑주 함수 𝐽(𝑤, 𝑤_0, α)로 변환
    3. 𝐽(𝑤, 𝑤_0, α)를 𝑤에 대해 편미분, 𝑤_0에 대해 편미분 하고 𝐽(𝑤, 𝑤_0, α)에 집어 넣어 정리하면 𝑄(α)를 얻음
    4. 𝑄(α) : 𝐽(𝑤, 𝑤_0, α)를 다른 형태로 표현한 목적함수 (이원적 문제라고도 함)
    5. 𝑄(α)를 최대화하는 α의 추정 값을 이차계획법을 이용해 도출, 이후 𝑤, 𝑤_0 추정
        - 보통 추정치(estimator)에 ^(hat/caret)을 표기
  - 결과  
    ![image](https://user-images.githubusercontent.com/61646760/193443474-bf87e87f-a289-4226-ac0a-7c98f95b6ce6.png)
    - 대부분의 학습 데이터에 대응되는 라그랑주 승수 α_hat_𝑖는 0이 됨
    - **서포트 벡터에 해당하는 α_hat_𝑖와 학습 데이터 (𝒙_𝑖, 𝑦_𝑖)만** 필요
      - 분류를 위해 저장할 데이터의 개수와 계산량의 현격한 감소
- SVM에 의한 분류  
  ![image](https://user-images.githubusercontent.com/61646760/193443886-80055389-ae83-46cd-828d-6994c7dbd8f1.png)
  - 서포트 벡터에 대해서만 𝑤_hat, 𝑤_hat_0 계산
    - 𝑋_𝑆 : 서포트 벡터만 모아 놓은 집합
- 정리 : 선형 SVM 분류기의 학습과 인식 단계  
  ![image](https://user-images.githubusercontent.com/61646760/193443957-e11ce06c-69c3-4ea5-b362-0e7474d57af9.png)  
  ![image](https://user-images.githubusercontent.com/61646760/193443967-844b5dec-d8f2-4a5c-9d6e-66f95000dcf9.png)
  - 즉, 학습을 통해 α_hat과 𝑤_hat_0를 얻어 내고, 실질적 계산은 𝑓(𝒙)를 통해 수행함
- 다중 클래스 분류 문제에의 적용
  - 서포트 벡터는 이진 분류 → 선택지가 둘 이상일 때는?
  - **1대 나머지 방법(one-versus-the-rest)**
    - 가장 보편적인 방법
    - 𝑘개의 개별적인 SVM 분류기 사용
    - 𝑘번째 SVM : 𝑘번째 클래스와 나머지 𝑘−1개의 클래스를 분류
      - 클래스 𝐶_𝑘에 해당하는 데이터는 +1이 되도록 학습
      - 나머지 𝑘-1개의 클래스의 데이터에 대해서는 -1이 되도록 학습
    - 문제
      - 애매모호한 결정 영역
      - 학습 데이터 집합의 크기가 불균형적
  - **1대1 방법(one-versus-one)**
    - 가능한 모든 클래스의 쌍에 대한 서로 다른 𝑘(𝑘-1)/2개의 SVM과 보팅 사용
    - 문제
      - 애매모호한 결정 영역
      - 학습/테스트를 위한 높은 계산 비용
- 슬랙변수를 가진 SVM
  - **슬랙변수 ξ(ksi)**
    - 잘못 분류된 데이터로부터 해당 클래스의 결정경계까지의 거리  
      ![image](https://user-images.githubusercontent.com/61646760/193445068-87270824-2434-404d-8c6b-93eb9039ab09.png)
    - 선형 분리가 불가능한 데이터 처리를 위해 도입
  - 슬랙변수를 포함한 분류 조건  
    ![image](https://user-images.githubusercontent.com/61646760/193445114-f4b84bc2-8072-4c3b-8326-a414f976fdbc.png)
    - ξ_𝑖가 크다는 것은 결정경계로부터 많이 올라갈/내려갈 수 있다는 것
      - 즉, 슬랙변수의 값이 클수록 더 심한 오분류를 허용!
  - 슬랙변수를 가진 SVM의 파라미터 추정  
    ![image](https://user-images.githubusercontent.com/61646760/193445231-8e065cd3-e28c-497d-a51e-c5d9014b5426.png)
    - 𝐽(𝑤, ξ)를 최소화하는 것이 목적
      - ξ_𝑖의 합이 커지는 것을 막기 위해 넣은 것이 𝑐
    - 두 조건을 동시에 만족하는 라그랑주 함수를 생성
      - 이전에는 라그랑주 함수가 `0 ≤ α_hat_𝑖`였는데 슬랙변수로 인해 `0 ≤ α_hat_𝑖 < 𝑐`가 됨
    - 이원적 문제로 풀어서 해결하면 𝑤_hat과 𝑤_hat_0 도출
    - α_hat_𝑖가 정해지면 𝑤_hat, 𝑤_hat_0의 값은 슬랙변수가 없는 경우와 완전히 동일!
      - `0 ≤ α_hat_𝑖 < 𝑐` 제외
### 커널법
### 정리
- 서포트 벡터 머신(SVM) : 여러 개의 선형 결정경계 중, 일반화 오차를 최소화하기 위한 마진이라는 개념을 도입하여 분류하는 선형 분류기
- 슬랙 변수 : 선형 분리가 불가능한 경우를 위해 도입
- 커널법
  - 저차원의 입력을 고차원으로 변환(고차원 매핑)시켜 선형화하여 분류
  - 계산량의 증가에 따른 문제 해결을 위해 커널 함수 사용

## 9강. 신경망 (1)
### 신경망 개요
- 인공지능 접근 방법
  - 크게 2가지 접근 방법이 있음  
    ![image](https://user-images.githubusercontent.com/61646760/194739954-d90ccadb-785e-4428-ac8b-19eee87da928.png)
    - **Symbolic AI (기호주의)**
      - AI 초기의 접근 방법이므로, Classic AI라고도 함
      - 부울 논리 기반, 규칙 기반 지식 표현, 논리 중심의 지식 표현을 위한 Prolog라는 언어도 개발됨
        - 문제 처리 과정을 잘 알고 있는 경우에만 적용 가능
      - 1997년의 IBM Deep Blue가 세계 체스 챔피언 카스파로프를 이김
    - **Connectionist AI (연결주의)**
      - 아주 간단한 기능을 수행하는 소자들을 연결하여 병렬적, 분산적으로 문제를 처리하겠다는 패러다임
      - 인간의 두뇌를 모방 (Artificial Neural Networks)
        - 최초의 신경망인 퍼셉트론 모델
        - 퍼셉트론 모델이 좀 더 발전한 다층 퍼셉트론 모델
        - 다층 퍼셉트론 모델이 좀 더 발전한 딥러닝 모델
      - 명시적 지식의 표현이 어려울 때도 적용 가능 (일반화된 규칙 찾기)
- **신경망(neural networks)**
  - 생물학적 신경회로망을 모델링한 수학적 함수
  - 원하는 입출력 매핑 함수의 형태를 스스로 찾는 학습 능력을 가짐
  - 데이터를 이용하여 학습이 수행되므로 데이터 분석 툴로 사용
  - 학습 방식(데이터 분석 용도)에 따라 다양한 모델이 존재
  - 신경망 연구
    - 인간 뇌의 구조와 뇌에서 수행되는 정보처리 방식을 모방함으로써 인간이 지능적으로 처리하는 복잡한 정보처리 능력을 기계를 통해 실현하고자 하는 연구
- **심층 신경망(deep networks)**
  - 가장 발전된 형태의 신경망 모델들
- **딥러닝(deep learning)**
  - 심층 신경망을 이용하여 데이터를 분석하는 머신러닝 기술
- 생물학적 신경망
  - 신경세포(neuron)의 구조와 연결  
    ![image](https://user-images.githubusercontent.com/61646760/194740982-c10d8012-9584-4699-86ea-70adbe96cd60.png)
    - 수상돌기 : 입력을 받는 부분
    - 세포체 : 입력의 합이 역치를 넘으면 신호 발생(activate)
    - 축색 : 절연체로 쌓여 있는 신호 전달의 통로(= 출력)
    - 시냅스 : 뉴런 간 연결 부분 (가중치에 따라 +, - 다르게 전달)
- **인공 신경망(artificial neural networks)**
  - 인간 뇌의 정보처리 방식을 모델링하는 방법
  - 인공 신경망의 구성 요소
    - **(인공) 신경세포(neuron, node, unit)**
      - 하나의 신경세포가 수행하는 기능을 수학적 함수로 정의
    - **신경망 구조(network structure)**
      - 신경세포들이 서로 정보를 전달하는 연결 구조
    - **학습 알고리즘(learning algorithm)**
      - 신경망이 원하는 기능을 수행할 수 있도록 신경세포들 간의 연결 강도를 조정(학습)하는 방법
#### 뉴런, 신경망 구조, 학습
- 인공 신경세포  
  ![image](https://user-images.githubusercontent.com/61646760/194741497-92b0c422-4e3e-4c34-86f1-ab34ec547c66.png)
  - `𝑢 = (𝑥_1 * 𝑤_1) + (𝑥_2 * 𝑤_2) + ... (𝑥_n * 𝑤_n)`
    - 활성화 함수 Ø는 𝑢가 역치(threshold)를 넘기면 1, 넘기지 않으면 0을 출력하도록 정의
  - **활성화 함수(activation function)**
    - 뉴런의 핵심 → 하나의 뉴런의 특성을 결정하는 역할  
      ![image](https://user-images.githubusercontent.com/61646760/194741985-5a93df9b-19e5-447a-8ca0-8500a2b4f23f.png)  
      ![image](https://user-images.githubusercontent.com/61646760/194742093-327a6b23-fd92-4577-a51f-fa000f0b8bc5.png)
      - 계단 함수(step function) : 𝑥=0에서 미분 불가능
      - 부호 함수(sign function) : 𝑥=0에서 미분 불가능
      - 선형 함수(linear function) : 가중합을 그대로 출력
      - 시그모이드 함수(sigmoid function) : 계단 함수와 유사. S자형 함수 (미분 가능)
      - 하이퍼탄젠트 함수(hyperbolic function) : 부호 함수와 유사. S자형 함수 (미분 가능)
      - ReLU 함수(Rectified Linear Unit function) : 0보다 작으면 0, 크면 선형 함수
- 신경망 구조
  - 신경세포들의 대표적 연결 방식
    - **다층 전방향 신경망(multi-layer feed forward neural network)**  
      ![image](https://user-images.githubusercontent.com/61646760/194742249-7a662b0d-707c-4a01-8d26-f1340e73cabe.png)
      - 층상 구조
      - 정보의 흐름이 전방향(feed-forward) : 입력층 to 출력층
      - 노드 간 완전 연결(fully connected network = dense network)
    - 은닉층의 존재 여부  
      ![image](https://user-images.githubusercontent.com/61646760/194742419-1eb6a173-16e9-4638-aea9-7af4026862e2.png)
        - 단층(single layer) 신경망 : 입력층과 출력층밖에 없음 (입력층은 전달 역할만 하므로 단층)
        - 다층(multilayer) 신경망
    - 정보 흐름의 방향  
      ![image](https://user-images.githubusercontent.com/61646760/194742444-24efd3e4-bff6-416a-ba0b-c264fbd8fea5.png)
        - 회귀(recurrent) 신경망(RNN) : 출력이 입력으로 제공, 층으로 구분돼 있지 않음 등등
- 학습 알고리즘
  - 인간 뇌의 학습
    - 성장하면서 뇌 세포들 간의 연결이 형성되어 여러 가지 기능을 수행하게 되는 과정
    - 세포들 간의 연결 형성 규칙
      - 연결된 두 신경세포가 동시에 활성화되면 연결 강도는 강해짐
        - `예) 파블로프의 개 실험` (후각/청각 세포 동시 활성화)
        - **Hebbian learning rule**
          - a neuroscientific theory claiming that an increase in synaptic efficacy arises from a presynaptic cell's repeated and persistent stimulation of a postsynaptic cell.
  - 인공 신경망의 학습이란?
    - 신경망이 원하는 기능을 수행할 수 있도록 만드는 것
    - 신경망에 어떤 입력 𝑥가 주어졌을 때, 최종적으로 내는 출력 𝑦가 원하는 값이 되도록 가중치 𝑤를 조정하는 것
      - 가중치 조정식  
        ![image](https://user-images.githubusercontent.com/61646760/194746998-820ad14c-6eb2-4201-b8b4-e426c2a9d6f9.png)
      - 가중치 변화량을 결정하는 방법
        - 학습 데이터 사용
      - 반복적인 가중치 수정을 통해 점점 원하는 기능에 근접해 감
  - 학습의 종류
    - **지도학습(supervised learning)**
      - 입력값 𝑥에 대한 목표 출력값 𝑡이 함께 주어짐
      - 주어진 입력 𝑥에 대한 신경망의 출력값 𝑦가 원하는 목표값 𝑡에 가까워지도록 가중치 𝑤를 수정
      - **오류 역전파 학습(error backpropagation learning) 알고리즘** : 지도학습을 수행하는 가장 대표적인 알고리즘
    - **비지도학습(unsupervised learning)**
      - 입력값 𝑥만 주어짐 → 비슷한 입력에 대해 비슷한 출력을 내도록 학습
      - self-organizing feature map, Boltzmann machine
    - **강화학습(reinforcement learning)**
      - 입력 𝑥에 대한 신경망의 출력값 𝑦의 보상이 최대가 되도록 가중치를 수정
#### 신경망의 응용적 이해
- 응용 관점에서의 신경망에 대한 이해
  - 하나의 **함수**로 취급  
    ![image](https://user-images.githubusercontent.com/61646760/194747859-a73ccb9b-4819-4f8f-afcc-09b50c8dab2a.png)
    - 기능 : 입력 𝑥를 받아 출력 𝑦를 계산
    - 수학적 정의 : `𝑦 = 𝑓(𝑥)`
  - 함수 𝑓를 결정하는 요소
    - 신경세포의 활성화 함수와 연결 구조는 고정된 형태
    - 연결 가중치 : 학습을 통해 함수 𝑓의 형태를 조정
      - 신경망의 학습이란 원하는 함수 𝑓를 찾는 과정
- 왜 신경망인가?
  - 표현(representation) 능력 : 신경망은 어떤 형태의 함수도 표현할 수 있음
  - 학습(learning) 능력 : 데이터에 대한 학습을 통해 최적의 함수를 찾을 수 있음
  - 일반화(generalization) 능력 : 데이터에 대한 단순한 암기가 아닌 데이터에서 일반화된 규칙을 찾음 → 새로운 데이터에 대해서도 처리 가능
### 다층 퍼셉트론
- **M-P 뉴런**
  - 1943년. MaCulloch & Pitts
  - 단일 신경세포에 대한 첫 번째 모델  
    ![image](https://user-images.githubusercontent.com/61646760/195245733-d139fc98-5ced-4599-a24d-34d439c84997.png)
    - Σ(입력과 가중치를 곱한 가중합 + 바이어스)
      - 바이어스는 역치로 보면 됨
      - 𝑤_(𝑖𝑗)𝑥_𝑖가 바이어스 𝑤_0𝑗보다 크면 Ø(𝑢)는 1, 작으면 0
- **퍼셉트론(perceptron)**
  - 1958년. Rosenblatt
  - M-P 뉴런을 여러 개 결합하여 네트워크 형태를 갖춘 신경망
    - 패턴인식을 수행하는 최초의 신경망
    - 단층 전방향 신경망
  - 뉴런, 연결 구조, 학습 규칙
    - 뉴런
      - M-P 뉴런 → 계단함수  
        ![image](https://user-images.githubusercontent.com/61646760/195246847-1a2c3866-df24-41fd-a074-7965a18c91fa.png)
    - 연결 구조
      - 단층, 전방향, 완전 연결(fully-connected)  
        ![image](https://user-images.githubusercontent.com/61646760/195247119-698ed392-69f1-4a76-82fb-149f1527f7a9.png)
    - 학습 규칙
      - 이진 입출력을 사용한 지도학습
  - 학습 규칙  
    ![image](https://user-images.githubusercontent.com/61646760/195247444-58d951d0-a2eb-4665-89fe-20c63be7d011.png)
    - 목표 출력과 실제 출력이 같으면 `목표 출력 - 실제 출력 = 0`이 되므로 가중치 변화 없음
    - 목표 출력과 실제 출력이 다르면 오차만큼 가중치를 변화해 주는데, 이때 에타(η)라는 상수 값을 사용해 변화량 설정
  - 퍼셉트론의 한계
    - 선형 판별함수
      - 비선형 결정경계를 표현할 수 없음
    - **XOR 문제**
      - Minsky & Papert가 XOR 문제의 해결 불가능을 지적 → 1차 암흑기  
        ![image](https://user-images.githubusercontent.com/61646760/195247909-281d3402-2d35-4a83-b5ac-f2cd437862b6.png)
        - 하나의 직선으로는 주황색 점들과 흰색 점들을 구분할 수 없음
        - 두 개의 직선(z1, z2)이 필요함
          - 중간에 층을 하나 더 넣는 것으로 가능함 → 다층 퍼셉트론
- **다층 퍼셉트론(MLP, Multi-Layer Perceptron)**
  - 1개 이상의 은닉층을 가짐  
    ![image](https://user-images.githubusercontent.com/61646760/195249065-e364b874-95c0-4c3d-ae73-2ff03cb8c139.png)
    - 2개 이상도 가능하지만 MLP는 보통 1개의 은닉층을 사용
  - 뉴런, 연결 구조, 학습 규칙
    - 뉴런
      - 출력은 입력에 대한 비선형 매핑  
        ![image](https://user-images.githubusercontent.com/61646760/195249207-edaf0141-28ab-4f67-8513-633a8386a9e1.png)
        - 은닉층에서는 무조건 시그모이드, 하이퍼탄젠트 함수(미분 가능한 함수들) 사용
        - 출력층에서는 다른 함수(선형함수 등)도 사용 가능
    - 연결 구조
      - 다층, 전방향, 완전 연결
    - 학습 규칙
      - **오류 역전파(error backpropagation) 알고리즘** → 지도학습
  - 다층 퍼셉트론의 입출력 관계  
    ![image](https://user-images.githubusercontent.com/61646760/195249610-c8c1ab42-530c-48b2-874d-194e96a2b928.png)  
    ![image](https://user-images.githubusercontent.com/61646760/195250497-ae8d90f4-8b77-4667-97f6-94e47c42d87d.png)
    - 하나의 은닉층을 가진 MLP는 임의의 정확도로 모든 연속 함수의 근사가 가능
    - 가중치를 적절히 조정함으로써 표현할 수 있는 함수의 형태가 매우 다양함  
      ![image](https://user-images.githubusercontent.com/61646760/195250154-901c2196-bfa7-45f3-b759-6fc1334cad35.png)
    - 입력 1개 - 출력 1개  
      ![image](https://user-images.githubusercontent.com/61646760/195250698-5b7e5a88-0163-4fc9-b210-b152e1426742.png)
      - 하나의 은닉층을 가진 MLP는 임의의 정확도로 모든 연속 함수의 근사가 가능!
    - 표현력이 좋은 건 좋은데, 함수를 찾기 위한 실제 학습은 어떻게 할 것인가? → 10강에서 다룰 것!

## 10강. 신경망 (2)
### 다층 퍼셉트론의 학습
- MLP의 수학적 표현  
  ![image](https://user-images.githubusercontent.com/61646760/195983299-65c8152b-3315-4a09-aef0-a04aab23a244.png)
  - `𝑥` : 입력 노드, 𝑛개
  - `𝑧` : 은닉 노드, 𝑚개
  - `𝑦` : 출력 노드, 𝑀개
  - `𝑤_𝑖𝑗` : 𝑥_𝑖와 𝑧_𝑗를 연결하는 가중치
  - `𝑣_𝑗𝑘` : 𝑧_𝑗와 𝑦_𝑘를 연결하는 가중치
  - `𝑢_𝑗^ℎ` : 𝑗번째 hidden 노드의 가중합
  - `𝑢_𝑘^𝑜` : 𝑘번째 출력 노드의 가중합
  - `Ø_ℎ` : 은닉 노드의 활성화 함수
  - `𝜃` : 𝑤, 𝑣 등의 패러미터 전체, 학습의 대상
- 다층 퍼셉트론의 학습
  - 신경망의 학습이란?
    - 원하는 함수를 나타내는 가중치(weight)를 찾는 것
  - MLP의 학습
    - 기본적으로 지도학습
      - 학습 데이터 집합은 입력과 목표 출력 값(𝑡)이 하나의 쌍으로 주어짐  
        ![image](https://user-images.githubusercontent.com/61646760/195984005-d0b350e1-ecf7-4ff0-86b2-e92daa2970e1.png)
        - 𝑥, 𝑡가 진한 까닭은 벡터이기 때문
    - 학습의 목적
      - 입력 𝒙_𝑖에 대한 신경망의 출력 𝒚_𝑖와 목표 출력 𝒕_𝑖의 차이를 최소화
    - 목적 함수로 오차함수를 사용 → 평균 제곱 오차  
      ![image](https://user-images.githubusercontent.com/61646760/195984045-8d0b2c0a-b2df-4eb1-b22e-c6dee3ea8091.png)
      - 최적의 가중치 `𝜃^*` : 오차함수 𝐸(𝑋, 𝜃)를 최소화하는 𝜃
  - 오차함수의 일반적 형태
    - 매우 복잡한 형태의 비선형 함수  
      ![image](https://user-images.githubusercontent.com/61646760/195986850-908b09ef-dff3-4c85-ae0f-c44160ca21a5.png)
      - **오류 역전파 학습 알고리즘(error backpropagation learning algorithm)** : 기울기 강하 학습법(gradient descent learning method)을 다층 퍼셉트론에 적용하여 알고리즘 형태로 구체화한 것
- **기울기 강하 학습법(gradient descent learning method)**  
  ![image](https://user-images.githubusercontent.com/61646760/195986974-255601ef-5fe9-42fe-8018-f0b6462f363f.png)
  - 미분을 통해 기울기를 파악(이 경우 벡터에 대한 미분이므로 편미분), 기울기가 줄어드는 방향으로 이동
  - η : 학습률
- **오류 역전파 학습 알고리즘(error backpropagation learning algorithm)**
  - 전체 도식  
    ![image](https://user-images.githubusercontent.com/61646760/195987765-d762b5f9-b0c5-424b-a8fe-7d5e44ed4794.png)
  - 현재 입력 𝑥에 대한 오차 함수 (온라인 학습 모드)  
    ![image](https://user-images.githubusercontent.com/61646760/195987446-23fdfe4d-e697-4395-bd5c-e7d188e07346.png)
    - 온라인 학습 모드 : 학습 데이터 전체가 아닌 학습 데이터 하나씩에 대해 학습을 수행하는 학습 방식
  - 은닉층에서 출력층으로의 가중치 𝑣_𝑗𝑘의 수정식  
    ![image](https://user-images.githubusercontent.com/61646760/195987460-8978e5ba-0e7f-42f3-91b8-966f0ebdd21a.png)
  - 입력층에서 은닉층으로의 가중치 𝑤_𝑖𝑗의 수정식  
    ![image](https://user-images.githubusercontent.com/61646760/195987655-9c02921d-9d90-4cc3-91fc-1d1487177be4.png)
### 응용: 숫자인식

## 12강. 딥러닝 (2)
### 기본 순환 신경망(RNN)
- 순환 신경망의 필요성
  - **순차 데이터(sequential data)**
    - 순서 정보를 가진 데이터
      - `예) 음성, 문장, 동영상, 주식 시세 등`
    - 특징
      - 데이터의 출현 순서가 중요
      - 데이터의 길이가 가변적
      - 데이터의 요소 사이에 **문맥적 의존성** 존재 → 이전 내용의 기억이 필요
  - **순환 신경망(RNN: recurrent neural networks)**
    - 시간에 따라 순차적으로 제공되는 데이터를 다루기 위한 모델
    - 응용 분야 : 기계번역, 음성 처리 등
- 기본적인 RNN 구조
  - **vanilla RNN**
    - 기본적인 RNN  
      ![image](https://user-images.githubusercontent.com/61646760/204553023-1fa12d49-95c8-47e3-bcb6-597a2fe70312.png)
      - 순환 신경망 : 전방향 신경망과 달리, 히든 노드 사이에 순환 엣지가 존재함
        - 즉 직전의 은닉 노드의 출력(직전의 정보)이 새로운 상태를 결정하기 위한 현재의 입력으로 사용된다는 의미
- RNN의 표현 방법
  - 축약된 표현  
    ![image](https://user-images.githubusercontent.com/61646760/204560123-53e56d01-c271-4457-aa0d-06b20b82301b.png)
    - `h_t-1` : 직전의 히든 노드의 상태
  - 전개된(unfolding) 구조  
    ![image](https://user-images.githubusercontent.com/61646760/204560269-aae5ed52-8fa6-40a5-9548-ddbc803d2172.png)
    - timestep
      - unfolding해서 보여 주는 것을 한번에 몇 개로 할 것인가
      - 위의 경우 1부터 t까지이므로 timestep은 t
- RNN의 순차적인 계산 과정  
  ![image](https://user-images.githubusercontent.com/61646760/204563480-5ba71653-247a-4036-ae83-d291631f3951.png)
  - 다층 퍼셉트론과의 차이
    - **계산이 순차적**으로 이루어진다는 것
    - **가중치를 공유**한다는 것 → 시스템의 복잡도를 낮출 수 있음
    - 입력, 히든 노드의 값이 스칼라 값이 아닌 벡터 값으로 보통 주어짐
- RNN 셀의 구조
  - 히든 노드, 즉 RNN의 셀(뉴런)의 구조  
    ![image](https://user-images.githubusercontent.com/61646760/204566176-676062a2-4b7e-482c-9413-aa38ad0244ce.png)
    - 직전 히든 노드의 상태와 현재의 입력을 받아 현재 히든 노드의 상태를 만들고, 최종 출력 노드 y를 출력
    - 히든 노드 `h_t`는 하이퍼탄젠트(Hyperbolic tangent)라는 활성화 함수를 거쳐 도출함 (히든 노드는 주로 하이퍼탄젠트 사용. ReLU를 쓰면 h가 너무 커질 수 있음)
    - 출력 노드 `y_t`는 소프트맥스(softmax)라는 활성화 함수를 거쳐 도출함 (출력 노드는 주로 소프트맥스 사용. sigmoid보다 기울기 소멸 문제에 보다 효과적)
- RNN 구조
  - 입출력 관계에 따른 다양한 구조와 응용  
    ![image](https://user-images.githubusercontent.com/61646760/204567839-137e7f95-8902-4011-a447-2fa865137131.png)
    - 1:1은 별다른 의미가 없음
    - 1:m은 하나의 입력을 받아 몇 번의 순환을 거쳐 출력 값을 도출
    - m:1은 여러 (시점의) 입력을 받아 최종적으로 단 하나의 출력 값을 도출
      - 필기를 할 때 순차적으로 가획이 이루어짐
    - m:n
      - 입력이 다 처리된 이후 출력이 만들어지는 경우
        - 하나의 문장에 대한 번역이 이루어지는 seq2seq과 같은 기계번역
      - 입력이 들어올 때마다 출력이 계속 만들어지는 경우
        - 동작 분류의 경우, 걸을 때 walking을 출력하다가 뛰면 running 출력
- RNN 구조의 확장  
  ![image](https://user-images.githubusercontent.com/61646760/204569922-16ebda3a-12c7-4adc-8bac-51f1c95ca075.png)
  - 다층 RNN
    - 은닉층을 여럿 쓰는 RNN
  - 양방향(bidirectional) RNN
    - 정보 전달이 양방향적으로 이루어지는 RNN (은닉층이 2개인 것이 아님!!)
    - 기계번역에 주로 활용됨 (뒤에서부터 정보를 가져오는 것이 보다 효과적인 경우가 있으므로)
- RNN 학습
  - 학습 데이터 집합  
    ![image](https://user-images.githubusercontent.com/61646760/204571024-1cdf2a86-a8f8-41c3-9058-8557950f9501.png)
    - 목표 출력 값 y가 주어지므로 지도 학습
  - 일정 timestep만 펼쳐 놓고 계산  
    ![image](https://user-images.githubusercontent.com/61646760/204571383-da5be931-706b-4ef4-84ee-da7d78dd747e.png)
    - 실제 출력 값 y_hat과 목표 출력 값 y 사이의 차이 = L
    - L1부터 Lt까지 전체를 모아 둔 것이 손실함수 L(W) = 오차함수
    - 학습의 목표는 **L(W)를 최소화하는 가중치 W**를 구하는 것
      - 학습 알고리즘은 오류 역전파 알고리즘을 시간 순서에 따라 변형시킨 <strong>시간 역전파 알고리즘(BPTT: Backpropagation Through Time)</strong>을 사용
    - 오차(역전파) 신호를 뒤로 전달하여 가중치들을 수정해 나감
      - 오차 신호는 활성화 함수의 미분 값과 가중치들의 곱으로 연속되어 표현됨
- RNN 학습의 문제  
  ![image](https://user-images.githubusercontent.com/61646760/204573010-bf212b2e-7ce4-4595-8b87-f86303fcd9e4.png)
  - **기울기 소멸(gradient vanishing) 문제**
    - 시점 1에서 t까지 길이(“timestep”)에 영향을 받음
    - 출력층의 오차 신호가 히든 노드를 거쳐 입력층으로 가는 도중에, 오차 신호가 점차 약해져 발생하는 문제
      - 심층 신경망의 층이 많으면 기울기 소멸 문제가 발생하나, RNN의 경우 층의 수와는 무관하고, t까지의 길이(timestep을 얼마나 펼칠 것인가)에 영향을 받음
  - **기울기 폭발(gradient explosion) 문제**
    - 기울기가 기하급수적으로 커지는 현상
    - 기울기 클리핑 : 기울기가 주어진 임계치보다 크면 그 값을 일정한 범위에 있도록 조정하는 해결 방법
### LSTM과 GRU
- RNN에서 가장 많이 사용되는 것이 LSTM, LSTM을 단순화한 것이 GRU
- LSTM?
  - 시간에 따른 입력 신호에 대한 민감도  
    ![image](https://user-images.githubusercontent.com/61646760/204736341-213a10fc-7e25-4206-9f7d-c9d12097a9f3.png)
    - 시간이 지남에 따라 전에 들어온 입력이 약해짐(희미해짐)
    - 6의 시점에서 1의 정보(입력)를 활용하고 싶다면? 불가능!
      - **장기 의존성(long-term dependency) 문제**
    - 해결 방법? 이전에 들어온 정보를 모두 기억하면 됨
      - **LSTM(Long Short Term Memory)**
    - LSTM은 각각의 노드 입출력 부분에 게이트가 있어 정도 조절이 가능
      - 원하는 시점까지 기억이 가능!
- LSTM 셀 구조
  - RNN 셀 vs LSTM 셀  
    ![image](https://user-images.githubusercontent.com/61646760/205072838-3e52104b-4877-42e2-99b2-ca8477987b43.png)
    - LSTM 셀이 RNN 셀보다 복잡함
      - 입력을 `c_{t-1}`도 받음 (입력 3개)
      - 기본 RNN은 순환되는 게 `h_t`뿐이지만, LSTM은 `h_t`와 `c_t` 2개가 순환됨
        - `h_t` : 셀의 출력을 만들어 내는 단기 기억 역할
        - `c_t` : 셀의 내부 상태를 기억하는 장기 기억 역할
    - 입력과 출력을 선별적으로 허용하여 출력을 제어하기 위한 게이트가 있음
      - 망각 게이트
      - 입력 게이트
      - 출력 게이트
- LSTM 셀의 기능  
  ![image](https://user-images.githubusercontent.com/61646760/205074146-5f949439-c97d-4b83-8d0d-1f3ffc1745d5.png)
  - 망각 게이트(forget gate)
    - 셀 상태 정보 `c_{t-1}`를 어느 정도 잊어버릴 것인가를 결정하는 부분  
      ![image](https://user-images.githubusercontent.com/61646760/205078625-e86bcb72-4ea9-4353-944f-c8fbc5923dd8.png)
      - **아다마르 곱(Hadamard product, ⊙)**
        - 같은 크기의 두 행렬의 각 성분을 곱하는 연산
        - 즉, 일반 행렬곱은 m x n과 n x p 꼴의 두 행렬을 곱하지만, 아다마르 곱은 m x n과 m x n 꼴의 두 행렬을 곱한다.
      - 0을 곱하면 완전 망각, 1을 곱하면 완전 기억(그대로)
  - 입력 게이트(input gate)
    - 셀 상태에 새로운 정보를 추가하는 정도를 조정하는 부분  
      ![image](https://user-images.githubusercontent.com/61646760/205085466-ac36af1a-66d1-4fe2-bf3a-8d21a84eb908.png)
      - `c tilde t` : 셀이 출력할 후보의 값
      - `i_t` : 입력 게이트. `c tilde t`를 셀 상태 갱신으로 전달할지를 결정
  - 셀 상태 갱신(cell-state update)
    - 새로운 셀 상태 `c_t`를 갱신하는 부분  
      ![image](https://user-images.githubusercontent.com/61646760/205086445-4df30b1c-5b5c-4f54-b207-5e932756696b.png)
      - 망각 게이트와 입력 게이트의 값 둘을 합하여 새로운 셀 상태 결정
  - 출력 계산
    - 출력 게이트와 셀의 출력을 계산하는 부분  
      ![image](https://user-images.githubusercontent.com/61646760/205086976-1ad134ad-50f3-45fe-8d69-0b043f03b5a9.png)
- **게이트 순환 유닛(GRU: Gated Recurrent Unit)**
  - LSTM 셀 구조를 단순하게 개선한 것
    - 2개의 입력(`ℎ_{t-1}`, `𝑥_t`), 하나의 출력(`ℎ_t`)
      - 셀 상태 `𝑐_t`는 없음 (LSTM은 있으므로 3개)
    - 2개의 게이트
      - 갱신 게이트(update gate) `𝑧_t` : 입력 게이트 + 망각 게이트
      - 리셋 게이트(reset gage) `𝑟_t`
- GRU 셀의 구조
  ![image](https://user-images.githubusercontent.com/61646760/205088113-5e1df36b-b02e-4d8c-a6e8-fdc7798642de.png)
  - 리셋 게이트
    - 이전의 출력을 어느 정도 받아들일지 조정하는 부분  
      ![image](https://user-images.githubusercontent.com/61646760/205088312-d33cacfb-06b9-4064-92ff-0723a1d9d236.png)
  - 갱신 게이트
    - 현 시점의 출력을 위해 받아들일 새로운 내용과 이전의 출력 내용의 비율을 조정  
      ![image](https://user-images.githubusercontent.com/61646760/205088415-04ceb6c9-715d-4a13-9dc7-96c70c117076.png)
  - 출력 `ℎ_t` 계산  
    ![image](https://user-images.githubusercontent.com/61646760/205088531-68d51a39-f29f-4500-b53b-6373e15ce321.png)

## 13강. 딥러닝 응용 (1)
### 컴퓨터비전 응용
- **컴퓨터 비전(Computer Vision)**
  - 영상 데이터를 주요 처리 대상으로 하여 인간의 다양한 시각적인 정보처리를 기계에 구현하려는 분야
    - 문제/주제의 종류는 매우 다양 : 카메라, 적외선 카메라, 레이더, X-ray, 초음파, CCTV, 블랙박스 등
  - 딥러닝 모델의 입력/출력을 기준으로 CV 응용의 구분
    - 영상 이해(image understanding)
    - 영상 변환(image transformation)
    - 영상 생성(image generation)
    - 다양한 입력 형태로의 확장
- **영상 이해(image understanding)**
  - 하나의 영상을 입력받아 그 안에 포함된 의미적 정보를 분석하여 추상적인 개념이나 정량적인 정보량을 출력
    - 정보량 : 객체 정보, 패턴 클래스, 두 영상 간의 의미적 유사도 등
  - 분류  
    ![image](https://user-images.githubusercontent.com/61646760/205241579-0b012e7f-e575-428c-a288-d0249cefbceb.png)
    - object recognition
      - 객체가 무엇인지 인식
      - 분류 문제로 볼 수 있음
    - object detection & localization
      - 객체 탐지 및 bounding box를 통한 객체 위치 출력
    - object description
      - 영상 안에 포함된 객체들의 의미 정보를 통합적으로 파악한 뒤 문장으로 설명
      - 이미지 캡셔닝과 동일
- **영상 변환(image transformation)**
  - 하나의 영상을 입력받아 그 안에 포함된 정보를 분석하여 원하는 형태로 변환된 새로운 영상을 출력
  - 분류  
    ![image](https://user-images.githubusercontent.com/61646760/205242646-3b3f0d0b-9c12-4bb6-817a-e66ce8abf5d6.png)
    - 영상 분할(image segmentation) : 군집화 문제
    - 영상 개선(image enhancement) : 해상도 향상 (`e.g. Super resolution`)
    - 기타 변환 : 다양한 효과 적용
  - **영상 분할(image segmentation)**
    - 의미적(semantic) 영상 분할  
      ![image](https://user-images.githubusercontent.com/61646760/205244038-0b97dfbe-517b-42fc-ac9e-bac2302e4318.png)
  - **Super Resolution**
    - 저해상도 영상을 고해상도 영상으로 복원하는 문제
      - SRCNN 2014, VDSR 2016, SRGAN 2017, EDSR 2017, DBPN 2018, …
      - DBPN (ICCV2018) : winner of super resolution challenges (NTIRE2018)
- **영상 생성(image generation)**
  - 출력으로 새로운 영상을 생성하는 일종의 창작 과정
    - “**GAN**” : 영상 생성을 위해 개발된 대표적인 딥러닝 모델  
      ![image](https://user-images.githubusercontent.com/61646760/205245221-96ebec6b-5815-455d-be88-3ca8e320ff38.png)
- 다양한 입력 형태로의 확장
  - 좀 더 다양한 형태의 입력을 다루는 모델들이 등장
    - 동영상, 3D 입체 영상 : 순환 연결을 가진 CNN, 3D CNN
  - **시각적 문답(Visual Question and Answering)**
    - 영상 신호 처리와 자연어 처리가 결합된 형태  
      ![image](https://user-images.githubusercontent.com/61646760/205245703-cfbbece9-4500-4979-9719-01f603395e73.png)
### 객체인식을 위한 CNN 모델
- 객체인식과 ILSVRC
  - **ImageNet Large-Scale Visual Recognition Challenge (ILSVRC, 2010)**
    - 객체 분류 및 위치 탐지(localization) 문제를 다루는 경진 대회 (현재는 X)
    - **ImageNet**
      - 영상 DB(Database)
      - 1,000개의 클래스와 120만 개의 영상 + 클래스 레이블을 지님
      - 이 데이터베이스를 바탕으로 지도 학습 수행!
  - 2012년 이후 딥러닝 모델이 우승을 차지  
    ![image](https://user-images.githubusercontent.com/61646760/205247221-b9ca90b7-9b57-4794-a0bc-fc44a5bf8fc5.png)
    - 딥러닝 모델을 사용한 SuperVision은 오류율이 16.4%로, 현저히 낮음
- **AlexNet**
  - Winner of 2012 (ILSVRC)
  - Krizhevsky et. al.
    - 2개의 CNN 구조 : 메모리 한계로 인해 듀얼 네트워크
    - 5개의 콘볼루션층, 3개의 완전연결층
- **VGG Net**
- **GoogLeNet**
- **ResNet**
### 영상이해를 위한 딥러닝
### 영상변환 및 생성을 위한 딥러닝

## 14강. 딥러닝 응용 (2)
### 자연어처리 응용
- **자연어 처리(NLP, Natural Language Processing)**
  - 컴퓨터로 자연어를 이해(understanding)하고, 번역(interpret)하고, 조작(manipulate)하기 위한 인공지능의 한 분야
    - 자연어(Natural language) : 정보 전달의 수단으로 인간 고유의 능력 (`e.g. 한국어, 영어 등`) 
    - 인공어(Artificial language) : 특정 목적을 위해 인위적으로 만든 언어 (`e.g. C, Python, Java 등`)
- 자연어처리의 구성 요소  
  ![image](https://user-images.githubusercontent.com/61646760/205424714-510a7827-cf00-43f1-9051-27eb6431c25c.png)
  - 형태소 분석
    - 문장을 이루는 최소 의미 단위인 형태소morpheme로 분리  
      ![image](https://user-images.githubusercontent.com/61646760/205424938-c1f1dcd7-e135-4c65-8fe0-258de246b938.png)
    - 형태소 분석의 어려움 → 중의성 ambiguity, 접두사/접미사 처리
    - 언어에 따라 난이도가 달라짐
  - 구문 분석(Parsing)
    - 주어진 문장의 구조를 문법에 맞춰 분석
      - 문법 : 문장의 구조적 성질을 규칙으로 표현한 것  
        ![image](https://user-images.githubusercontent.com/61646760/205424991-4d795fab-b8bb-418f-a238-5415b584abd6.png)
    - 어려움 : 구조적 중의성(structural ambiguity)
      - `예) Time flies like light.`
      - `예) A man see a woman with a telescope.`
  - 의미 분석
    - 구문 분석 결과에 의미를 가하여 문장이 가진 의미를 분석
    - 형태소가 가진 의미를 표현하는 지식표현 기법이 필요
    - 문법은 맞으나 의미적으로 틀린 문장을 검사
      - `예) 기차가 구름을 먹는다.`
    - 어려움 : 의미적 중의성
      - `예) 말이 많다.`
        - Many horses? chatty?
  - 화용 분석
    - 문장이 실제로 사용될 때 연관관계를 분석
    - **담화 분석(discourse analysis)**
      - 상호참조(coreference) : 대명사가 지시하는 대상 확인
        - `예) John’s boss said he was getting better.`
          - He는 누구?
      - 화행(speech act) 분석 : 발화의 의도 분석(정보요구, 정보제공, 거절 등)
        - `예) Can you give me a salt?`
          - Can의 의도는?
    - 실세계의 지식 표현이 필요
- 자연어처리의 어려움
  - 문법과 규칙에 기반 but 많은 예외사항이 존재
  - 모호성(중의성) 존재
    - 문맥 정보와 엄청난 양의 지식이 필요
  - 높은 차원
    - 많은 개수의 단어가 사용 → 효율적인 표현 방법이 필요
  - 순차적인 입력과 출력
    - 시퀀스가 중요 → 시퀀스 처리 능력이 필요
  - 머신러닝/딥러닝이 자연어처리의 좋은 도구가 될 수 있음!
- 자연어처리의 응용
  - 음성 신호처리(speech signal processing)
    - 음성인식(speech recognition), 화자인식(speaker recognition), 음성합성(speech synthesis)
  - 대화 수행(dialogue action)
    - 정보검색(information retrieval), 질의응답(question-answering), 목적 지향 대화(task-oriented dialogue)
  - 텍스트 분석(text analysis)
    - 텍스트 분류(text classification)
      - 스팸 필터링, 감성 인식(sentiment classification), 주제 분류(text categorization)
    - 기계번역(machine translation)
    - 텍스트 요약(text summarization)
- **음성 신호처리(speech signal processing)**
  - 사람의 목소리로 발화된 음성 신호에 포함된 언어 정보를 처리  
    ![image](https://user-images.githubusercontent.com/61646760/205425927-62194222-17c5-4ff3-b0ef-0db0d58b9e9b.png)
    - 음성인식(speech recognition) : STT(speech-to-text)
    - 화자인식(speaker recognition) : 고유 값을 통한 개인 구분
    - 음성합성(speech synthesis) : TTS(Text To Speech)
- **대화 수행(dialogue action)**
  - 상대방과 문장을 주고받는 형식으로 진행되는 작업
    - AI 스피커, 챗봇 등의 핵심 기술
    - **정보 검색(information retrieval)**
      - 사용자가 준 쿼리를 인터넷/데이터베이스에서 유관 문서를 찾아옴  
        ![image](https://user-images.githubusercontent.com/61646760/205426630-d4068143-d7ad-4d5f-9f68-11e535451e02.png)
    - **질의응답(question-answering) 시스템**
      - 정보를 검색해 순위를 매겨(ranking) 1위를 정답으로 산출  
        ![image](https://user-images.githubusercontent.com/61646760/205426711-3927a592-25c9-416a-8524-b8726330d154.png)
    - **목적 지향 대화(task-oriented dialogue) 시스템**
      - 예매 등 특정 목적을 충족하기 위한 대화  
        ![image](https://user-images.githubusercontent.com/61646760/205426923-3ef4c117-051a-4d56-b820-56d29825313d.png)
- **텍스트 분석(text analysis)**
  - 일련의 텍스트 정보를 입력으로 받아 그 의미적 내용과 문맥 등을 분석하여 원하는 결과를 도출
  - **텍스트 분류(text classification)**
    - 주어진 일련의 텍스트를 미리 정해진 몇 개의 클래스로 나누는 것
    - 감성인식, 주제 분류, 스팸 필터링 등  
      ![image](https://user-images.githubusercontent.com/61646760/205427280-fe7aaa1d-d05b-4e74-bee3-8eb1e7a73668.png)
  - **기계번역(machine translation)**
    - 문장을 입력받아 같은 의미를 가진 다른 언어의 문장을 생성
      - 고전적인 접근법  
        ![image](https://user-images.githubusercontent.com/61646760/205427331-529238d0-cb98-4aa3-babf-96e4072104b0.png)
      - 딥러닝 접근법(neural machine translator)  
        ![image](https://user-images.githubusercontent.com/61646760/205427359-73cd0064-ac81-48d4-95b2-84dbaed32504.png)
  - **텍스트 요약(text summarization)**
    - 긴 분량의 텍스트를 입력받아 짧게 요약된 문장으로 출력  
      ![image](https://user-images.githubusercontent.com/61646760/205427303-178c978e-69bf-4f9f-9527-b356c9b52dc3.png)
      - **추출 요약(extractive summarization)** : 가장 적절한 문장을 선택하여 조합 (sentence ranking을 통해 순위를 매김)
      - **추상적 요약(abstractive summarization)** : 새로운 문장을 사용하여 요약
### 자연어처리를 위한 머신러닝 기법
- NLP를 위한 ML 시스템 개발 단계  
  ![image](https://user-images.githubusercontent.com/61646760/205427789-2cc95b21-dd57-4b2d-a871-38edc68e93a8.png)
- NLP를 위한 데이터 수집
  - **텍스트 말뭉치(text corpus)**
    - 크고 구조화된 텍스트 데이터 집합
    - 주요 말뭉치
      - 구글 n-gram 말뭉치
      - COCA(Corpus of Contemporary American English)
      - 국립국어원 ‘모두의 말뭉치’
    - WordNet
      - a lexical database for English
- 텍스트 전처리
  - **토큰화(tokenization)**
    - 말뭉치를 의미 있는 기본 단위(“token”)으로 나누는 작업
    - 토큰의 기준 : 단어, 문장, 구 phrase, 형태소  
      ![image](https://user-images.githubusercontent.com/61646760/205428192-6dd640d1-b054-4528-b199-dbc8e4319b8b.png)
    - 고려 사항
      - 구두점, 특수문자의 처리
      - 줄임말, 단어 내 띄어쓰기
      - 한국어의 경우 조사, 어간과 어미 분리
  - 정제(cleaning), 정규화(normalization)
    - **정제(cleaning)**
      - 말뭉치로부터 데이터 분석에 방해되는 노이즈 데이터 제거
        - 불필요한 단어 제거 → 등장 빈도가 적은 단어, 길이가 짧은 단어(예: it, at, to, on, in, by, …)
        - 정규표현식을 사용하여 특정 표현 제거
          - `예) 해시태그, 기사의 날짜 등`
    - **정규화(normalization)**
      - 표현 방법이 다른 단어들을 하나의 단어로 통합시키는 것
        - 표기가 다른 단어들의 통합
          - `예) US, USA`
        - 대소문자 통합
  - 토큰의 품사 태깅 작업  
    ![image](https://user-images.githubusercontent.com/61646760/205428297-9be955e1-f225-4af0-a5b4-e9cf10a84623.png)
- 데이터 표현
  - **원핫인코딩(one-hot encoding)**
    - 말뭉치로부터 획득한 단어집합 vocabulary의 각 단어를 고유 정수로 매핑한 후 원핫벡터로 표현
      - m개의 단어가 있는 경우 : m차원 원핫벡터  
        ![image](https://user-images.githubusercontent.com/61646760/205428361-dc46632a-07bd-4bc3-b3e4-e668aa47f6a9.png)  
        ![image](https://user-images.githubusercontent.com/61646760/205428375-604bd2e7-24b5-4419-a119-fb2df3e95ef4.png)
        - 단어가 9개라 9차원이 됨
        - sparse하기 때문에 효율성이 떨어짐
    - 한계점
      - 단어수가 많아지면 차원이 높아짐
      - 단어 간의 유사도 반영 불가
  - **BoW(Bag of Words)**
    - 단어의 출현 빈도수(frequency)를 고려한 텍스트 표현 방법
      1. 단어집합에 포함된 각 단어에 고유한 정수 인덱스를 부여  
          ![image](https://user-images.githubusercontent.com/61646760/205429301-4220fcbb-d818-41f7-ba0f-130104512eec.png)
      2. 주어진 입력 텍스트에 대하여 각 단어의 출현 횟수를 계산  
          ![image](https://user-images.githubusercontent.com/61646760/205429335-37434a32-5eee-45bf-9e42-5d43a0f9034d.png)
      3. 각 단어의 대응 위치(인덱스)에 출현 회수를 정수 값으로 표현  
          ![image](https://user-images.githubusercontent.com/61646760/205429353-ebf195ae-cefe-4d5c-8fbe-7ecbd28c22ae.png)
    - 문서에 자주 출현하는 단어가 잘 표현됨. 하지만 단어의 발생 위치는 고려되지 않음
      - 위에서 수박의 빈도는 2임
      - 빈도 수를 이용해 간단한 문장 간 유사도 평가나 주제 분류 수행도 가능함
  - **TF-IDF(Term Frequency-Inverse Document Frequency)**
    - **문서-단어 행렬(Document-Term Matrix)**
      - 다수 문서에 등장하는 각 단어들의 빈도수를 표현한 행렬  
        ![image](https://user-images.githubusercontent.com/61646760/205429484-ba7b596e-c95c-4007-9e3f-b02c53580913.png)
        - 행은 '문서 수', 열은 '단어의 개수'
        - 1행만 놓고 보면, **문서1에 대한 BoW를 계산한 것과 동일**함!
    - **단어 빈도(Term Frequency)**
      - **TF(d, t)** : 문서 d에서 단어 t가 나타나는 횟수
    - **문서 빈도(Document Frequency)**
      - 각 단어가 나타나는 문서의 빈도수를 계산  
        ![image](https://user-images.githubusercontent.com/61646760/205429500-5af972f6-d344-490a-ab5f-91bf10a84d8c.png)
        - '먹고'는 문서1과 문서2에서 총 2번 나타남
    - 즉, TF-IDF는 TF와 DF를 이용해서 계산한 것
      - 어떤 단어가 여러 문서에서 많이 등장했다면, 해당 단어는 문서의 특성을 잘 나타내는 단어라고 보기는 어려움 (대명사, 관사 등)
    - **IDF(Inverse Document Frequency)**
      - 단어 t가 등장하는 문서의 개수 DF(t)에 반비례하는 값
      - 왜 반비례?
        - 여러 문서에 많이 나타나면 중요도가 덜함 
    - TF-IDF란?
      - **문서 내의 각 단어의 빈도수와 문서의 빈도를 함께 고려한 표현 방식**  
        ![image](https://user-images.githubusercontent.com/61646760/205429678-b0ca1418-9e8a-43fb-b425-52a0096ac1bf.png)
        - N은 문서의 수. 값이 기하급수적으로 커지는 걸 막기 위해 log를 씌움
        - 어떤 단어는 아무 문서에도 등장하지 않을 수도 있으므로, 실제로는 분모 DF(t)에 1을 더해서 계산함
      - 특정 문서에 국한된 단어는 큰 값, 일반적인 공용 단어는 낮은 값
- 데이터 분석
  - **워드 임베딩(word embedding)**
    - 단어의 의미를 포함하는 벡터(“임베딩 벡터”)로 표현하는 방법
      - 원핫벡터를 저차원 실수 공간의 벡터로 변환  
        ![image](https://user-images.githubusercontent.com/61646760/205429972-94ec6e73-c453-422d-b147-6d9a6d32371b.png)
    - 목적 : 유사한 의미의 단어를 가까운 위치에 표현
    - 대표적 방법 : Word2Vec (CBoW, Skip-gram)
- **Word2Vec**
  - 원핫벡터를 저차원의 벡터로 변환하는 선형변환행렬 𝑊를 학습으로 찾고, 이를 이용하여 입력 단어를 사영함으로써 임베딩 벡터를 구함
    - 말뭉치의 문맥 정보를 활용하여 학습을 수행
    - 은닉층이 1개인 간단한 구조의 신경망 사용
  - 학습 방식에 따라 두 가지 모델이 존재
    - **CBoW(Continuous Bag of Words)**
      - 주변 단어(문맥 앞뒤의 𝑛개 단어)들을 입력으로 받아 중심 단어를 예측
    - **Skip-gram**
      - 중심 단어를 입력으로 받아 주변 단어들을 예측
  - Word2Vec의 수행 과정  
    ![image](https://user-images.githubusercontent.com/61646760/205430644-cbfc1edf-d6af-409d-9127-a87a6c000117.png)
    - sliding window가 2이므로 중심 단어(center word)를 기준으로 좌우에 2개의 문맥 단어(context word)가 있음
    - CBoW 모델은 문맥 단어들을 입력으로 받아 중심 단어를 출력
    - Skip-gram 모델은 중심 단어를 입력으로 받아 주변의 문맥 단어들을 출력
    - 중간의 layer는 hidden layer가 아니라 projection layer
      - 활성화 함수가 없고 룩업 테이블이라는 연산을 수행함
    - Skip-gram이 CBoW보다 많이 사용되는 경향이 있음
  - Word2Vec의 수행 결과의 예  
    ![image](https://user-images.githubusercontent.com/61646760/205430697-64378856-2ffd-4b6d-a697-5d1f0d9d247e.png)
    - 단어 → 원핫벡터 → 임베딩벡터 → 2차원으로 변환한 결과
    - 단어의 의미적 관계가 표현되고 있음
      - `예) man-woman, king-queen 등`
    - 벡터 간 연산이 가능함
      - 의미에 대한 연산이 가능하다는 의미!
      - `예) 사랑+이별+만남 = 인연`
### 언어 모델을 위한 딥러닝
